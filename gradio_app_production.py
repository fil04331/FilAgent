#!/usr/bin/env python3
"""
FilAgent - Interface Gradio Production
Version: 1.0.0
Date: 2024-11-14
Auteur: F√©lix Lefebvre

Interface professionnelle pour FilAgent avec architecture modulaire,
respect des bonnes pratiques et √©volutivit√© garantie.
Conforme aux standards: Loi 25, RGPD, AI Act, ISO 27001
"""

from __future__ import annotations

import asyncio
import hashlib
import json
import logging
import os
import sqlite3
import traceback
import uuid
from concurrent.futures import ThreadPoolExecutor
from dataclasses import asdict, dataclass, field
from datetime import datetime, timezone
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union

# Type Aliases for strict typing
JSONValue = Union[str, int, float, bool, None, Dict[str, "JSONValue"], List["JSONValue"]]
MessageContent = Union[str, Dict[str, str], List[str]]
APIResponse = Dict[str, Union[str, int, bool, List[str], Dict[str, JSONValue]]]
ChatHistory = List[List[str]]
MetadataDict = Dict[str, Union[str, int, float, bool, None]]
ComplianceChecks = Dict[str, bool]
ProvenanceData = Dict[str, str]
IntentDict = Dict[str, Union[str, float, bool]]
ToolMapping = Dict[str, List[str]]

import gradio as gr
import pandas as pd
from cryptography.exceptions import InvalidSignature
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.primitives.asymmetric import ed25519
from dotenv import load_dotenv

# Importation des outils
from tools.document_analyzer_pme import DocumentAnalyzerPME
from tools.python_sandbox import PythonSandboxTool
from tools.file_reader import FileReaderTool
from tools.calculator import CalculatorTool
from tools.base import ToolStatus

# Charger les variables d'environnement (.env) - IMPORTANT pour les API keys
load_dotenv()

# Configuration logging structur√©
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# ============================================================================
# CONSTANTES ET VALIDATION POUR DOCUMENT ANALYZER (Phase 6.1)
# ============================================================================

# Limites de s√©curit√© pour les fichiers
MAX_FILE_SIZE_MB = 50  # Taille maximale: 50 MB
MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024
MAX_PREVIEW_ROWS = 100  # Lignes max pour aper√ßu Excel
MAX_PREVIEW_PARAGRAPHS = 100  # Paragraphes max pour aper√ßu Word
PROCESSING_TIMEOUT_SECONDS = 30  # Timeout pour traitement

# Extensions support√©es
SUPPORTED_EXTENSIONS = {
    "pdf": [".pdf"],
    "excel": [".xlsx", ".xls", ".xlsm"],
    "word": [".docx", ".doc"],
}
ALL_SUPPORTED_EXTENSIONS = [ext for exts in SUPPORTED_EXTENSIONS.values() for ext in exts]

# Messages d'erreur standardis√©s
ERROR_MESSAGES = {
    "file_not_found": (
        "‚ùå **Fichier introuvable**\n\n"
        "Le fichier n'existe pas ou a √©t√© supprim√©.\n\n"
        "üí° **Solutions**:\n"
        "1. V√©rifiez que le fichier existe toujours √† cet emplacement\n"
        "2. Essayez de t√©l√©verser le fichier √† nouveau\n"
        "3. V√©rifiez les permissions d'acc√®s au fichier"
    ),
    "file_too_large": (
        f"‚ùå **Fichier trop volumineux**\n\n"
        f"Taille maximale autoris√©e: {MAX_FILE_SIZE_MB} MB\n\n"
        "üí° **Solution**: Essayez avec un fichier plus petit ou divisez-le en plusieurs parties."
    ),
    "unsupported_format": (
        "‚ùå **Format non support√©**\n\n"
        "**Formats accept√©s**:\n"
        "‚Ä¢ PDF (`.pdf`)\n"
        "‚Ä¢ Excel (`.xlsx`, `.xls`, `.xlsm`)\n"
        "‚Ä¢ Word (`.docx`, `.doc`)\n\n"
        "üí° **Solution**: Convertissez votre fichier dans un format support√©."
    ),
    "permission_denied": (
        "‚ùå **Acc√®s refus√©**\n\n"
        "Impossible de lire le fichier (permissions insuffisantes).\n\n"
        "üí° **Solution**: V√©rifiez les permissions du fichier."
    ),
    "corrupted_file": (
        "‚ùå **Fichier corrompu**\n\n"
        "Le fichier ne peut pas √™tre lu correctement.\n\n"
        "üí° **Solutions**:\n"
        "1. Ouvrez le fichier avec son application native pour v√©rifier\n"
        "2. Essayez de r√©enregistrer le fichier\n"
        "3. Utilisez un autre fichier"
    ),
    "password_protected": (
        "‚ùå **Fichier prot√©g√©**\n\n"
        "Le fichier est prot√©g√© par mot de passe.\n\n"
        "üí° **Solution**: Supprimez la protection par mot de passe avant l'analyse."
    ),
    "memory_error": (
        "‚ùå **M√©moire insuffisante**\n\n"
        "Le fichier est trop complexe pour √™tre trait√©.\n\n"
        "üí° **Solutions**:\n"
        "1. Essayez avec un fichier plus petit\n"
        "2. Simplifiez le contenu du fichier\n"
        "3. Fermez d'autres applications"
    ),
    "timeout": (
        f"‚è±Ô∏è **Traitement trop long**\n\n"
        f"Le traitement a d√©pass√© {PROCESSING_TIMEOUT_SECONDS} secondes.\n\n"
        "üí° **Solutions**:\n"
        "1. Essayez avec un fichier plus simple\n"
        "2. R√©duisez la taille du fichier"
    ),
    "disk_space": (
        "‚ùå **Espace disque insuffisant**\n\n"
        "Impossible de cr√©er les fichiers d'export.\n\n"
        "üí° **Solution**: Lib√©rez de l'espace disque."
    ),
    "export_failed": (
        "‚ùå **Erreur d'export**\n\n"
        "Impossible de cr√©er le fichier d'export.\n\n"
        "üí° **Solutions**:\n"
        "1. V√©rifiez l'espace disque disponible\n"
        "2. R√©essayez l'op√©ration\n"
        "3. Contactez le support si le probl√®me persiste"
    ),
}


class FileValidationError(Exception):
    """Exception personnalis√©e pour les erreurs de validation de fichiers"""

    pass


def validate_file(file_path: str) -> Tuple[bool, Optional[str]]:
    """
    Valider un fichier avant traitement avec s√©curit√© renforc√©e

    Security: Validates path against allowlist to prevent path traversal attacks

    Args:
        file_path: Chemin du fichier √† valider

    Returns:
        Tuple[bool, Optional[str]]: (is_valid, error_message)
    """
    try:
        path = Path(file_path)

        # Security: Check for null byte injection
        if "\0" in file_path:
            return False, "‚ùå **Erreur de s√©curit√©**: Caract√®re null d√©tect√© dans le chemin"

        # Security: Check path length
        if len(file_path) > 4096:
            return False, "‚ùå **Erreur**: Chemin trop long (max 4096 caract√®res)"

        # 1. V√©rifier existence
        if not path.exists():
            return False, ERROR_MESSAGES["file_not_found"]

        # Security: Validate path is in allowed directories
        # Allow Gradio's temporary upload directory and configured allowed paths
        allowed_paths = [
            "working_set/",
            "temp/",
            "memory/working_set/",
            "/tmp/",  # Gradio uploads to system temp
        ]

        try:
            path_resolved = path.resolve(strict=True)
            is_allowed = False

            for allowed in allowed_paths:
                try:
                    allowed_resolved = Path(allowed).resolve()
                    # Check if path is under allowed directory
                    path_resolved.relative_to(allowed_resolved)
                    is_allowed = True
                    break
                except ValueError:
                    continue

            if not is_allowed:
                logger.warning(f"‚ö†Ô∏è Blocked access to unauthorized path: {file_path}")
                return (
                    False,
                    "‚ùå **Erreur de s√©curit√©**: Acc√®s au fichier refus√© (chemin non autoris√©)",
                )

        except (OSError, RuntimeError) as e:
            logger.error(f"Path validation error: {e}")
            return False, f"‚ùå **Erreur de validation**: {str(e)}"

        # 2. V√©rifier extension
        if path.suffix.lower() not in ALL_SUPPORTED_EXTENSIONS:
            return False, ERROR_MESSAGES["unsupported_format"]

        # 3. V√©rifier taille
        file_size = path.stat().st_size
        if file_size > MAX_FILE_SIZE_BYTES:
            actual_size_mb = file_size / (1024 * 1024)
            return (
                False,
                ERROR_MESSAGES["file_too_large"]
                + f"\n\n**Taille actuelle**: {actual_size_mb:.1f} MB",
            )

        # 4. V√©rifier permissions
        if not path.is_file():
            return False, "‚ùå Le chemin ne pointe pas vers un fichier valide"

        # 5. Tester lecture (premiers bytes)
        try:
            with open(path, "rb") as f:
                f.read(100)  # Lire 100 premiers bytes
        except PermissionError:
            return False, ERROR_MESSAGES["permission_denied"]
        except IOError as e:
            return False, f"‚ùå Erreur de lecture: {str(e)}"

        return True, None

    except Exception as e:
        logger.error(f"Erreur validation fichier: {e}")
        return False, f"‚ùå Erreur de validation: {str(e)}"


def check_disk_space(required_bytes: int = 100 * 1024 * 1024) -> bool:
    """
    V√©rifier l'espace disque disponible

    Args:
        required_bytes: Espace requis en bytes (d√©faut: 100 MB)

    Returns:
        bool: True si espace suffisant
    """
    try:
        import shutil

        total, used, free = shutil.disk_usage("/")
        return free >= required_bytes
    except Exception as e:
        logger.warning(f"Impossible de v√©rifier l'espace disque: {e}")
        return True  # Continuer par d√©faut si impossible de v√©rifier


def cleanup_temp_files(*file_paths: Optional[str]) -> None:
    """
    Nettoyer les fichiers temporaires

    Args:
        *file_paths: Chemins des fichiers √† supprimer
    """
    for file_path in file_paths:
        if file_path:
            try:
                path = Path(file_path)
                if path.exists() and path.is_file():
                    path.unlink()
                    logger.debug(f"Fichier temporaire supprime: {file_path}")
            except Exception as e:
                logger.warning(f"Impossible de supprimer {file_path}: {e}")


# ============================================================================
# CONFIGURATION GLOBALE
# ============================================================================


@dataclass
class FilAgentConfig:
    """Configuration centralis√©e de FilAgent"""

    # Paths - Use environment variable or detect from file location
    base_dir: Path = field(
        default_factory=lambda: Path(
            os.environ.get("FILAGENT_BASE_DIR", str(Path(__file__).parent.resolve()))
        )
    )
    db_path: Optional[Path] = None
    logs_dir: Optional[Path] = None
    keys_dir: Optional[Path] = None
    models_dir: Optional[Path] = None

    # API
    api_host: str = "localhost"
    api_port: int = 8000
    api_timeout: int = 30

    # Securite
    enable_pii_redaction: bool = True
    enable_audit_trail: bool = True
    enable_decision_records: bool = True
    max_message_length: int = 10000

    # Conformite
    retention_days: int = 90
    jurisdiction: str = "QC-CA"
    compliance_frameworks: List[str] = field(default_factory=list)

    # Performance
    max_workers: int = 4
    cache_ttl: int = 3600
    batch_size: int = 32

    def __post_init__(self) -> None:
        self.db_path = self.base_dir / "memory" / "episodic" / "conversations.db"
        self.logs_dir = self.base_dir / "logs"
        self.keys_dir = self.base_dir / "provenance" / "keys"
        self.models_dir = self.base_dir / "models" / "weights"

        if not self.compliance_frameworks:
            self.compliance_frameworks = ["LOI25", "GDPR", "AI_ACT", "ISO27001"]


# ============================================================================
# MOD√àLES DE DONN√âES
# ============================================================================


class MessageRole(Enum):
    """R√¥les des messages dans la conversation"""

    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"
    TOOL = "tool"


@dataclass
class Message:
    """Modele de message avec metadonnees completes"""

    id: str
    role: MessageRole
    content: str
    timestamp: datetime
    conversation_id: str
    pii_redacted: bool = False
    metadata: Optional[MetadataDict] = None
    signature: Optional[str] = None

    def to_dict(self) -> Dict[str, Union[str, bool, MetadataDict, None]]:
        """Convertir en dictionnaire pour serialisation"""
        data = asdict(self)
        data["role"] = self.role.value
        data["timestamp"] = self.timestamp.isoformat()
        return data


@dataclass
class DecisionRecord:
    """Enregistrement de decision pour conformite"""

    id: str
    conversation_id: str
    timestamp: datetime
    input_hash: str
    output_hash: str
    model_version: str
    temperature: float
    tools_used: List[str]
    compliance_checks: ComplianceChecks
    signature: str
    provenance: ProvenanceData


@dataclass
class ComplianceMetrics:
    """M√©triques de conformit√© en temps r√©el"""

    total_decisions: int = 0
    pii_redactions: int = 0
    audit_records: int = 0
    signatures_verified: int = 0
    retention_compliant: bool = True
    last_audit: Optional[datetime] = None


# ============================================================================
# GESTIONNAIRE DE S√âCURIT√â ET CRYPTOGRAPHIE
# ============================================================================


class SecurityManager:
    """Gestionnaire de securite avec signatures EdDSA"""

    config: FilAgentConfig
    private_key: Optional[ed25519.Ed25519PrivateKey]
    public_key: Optional[ed25519.Ed25519PublicKey]

    def __init__(self, config: FilAgentConfig) -> None:
        self.config = config
        self.private_key = None
        self.public_key = None
        self._load_keys()

    def _load_keys(self) -> None:
        """Charger les cles EdDSA depuis le systeme de fichiers"""
        try:
            if self.config.keys_dir is None:
                logger.warning("keys_dir non configure, generation des cles...")
                self._generate_keys()
                return

            private_key_path = self.config.keys_dir / "private_key.pem"
            public_key_path = self.config.keys_dir / "public_key.pem"

            if private_key_path.exists() and public_key_path.exists():
                with open(private_key_path, "rb") as f:
                    loaded_private = serialization.load_pem_private_key(f.read(), password=None)
                    if isinstance(loaded_private, ed25519.Ed25519PrivateKey):
                        self.private_key = loaded_private

                with open(public_key_path, "rb") as f:
                    loaded_public = serialization.load_pem_public_key(f.read())
                    if isinstance(loaded_public, ed25519.Ed25519PublicKey):
                        self.public_key = loaded_public

                logger.info("Cles EdDSA chargees avec succes")
            else:
                logger.warning("Cles EdDSA non trouvees, generation...")
                self._generate_keys()
        except Exception as e:
            logger.error(f"Erreur chargement cles: {e}")
            self._generate_keys()

    def _generate_keys(self) -> None:
        """Generer nouvelles cles EdDSA si necessaire"""
        self.private_key = ed25519.Ed25519PrivateKey.generate()
        self.public_key = self.private_key.public_key()

        if self.config.keys_dir is None:
            logger.warning("keys_dir non configure, cles en memoire uniquement")
            return

        # Creer le repertoire si necessaire
        self.config.keys_dir.mkdir(parents=True, exist_ok=True)

        # Sauvegarder les cl√©s
        private_pem = self.private_key.private_bytes(
            encoding=serialization.Encoding.PEM,
            format=serialization.PrivateFormat.PKCS8,
            encryption_algorithm=serialization.NoEncryption(),
        )

        public_pem = self.public_key.public_bytes(
            encoding=serialization.Encoding.PEM,
            format=serialization.PublicFormat.SubjectPublicKeyInfo,
        )

        (self.config.keys_dir / "private_key.pem").write_bytes(private_pem)
        (self.config.keys_dir / "public_key.pem").write_bytes(public_pem)

        # Securiser la cle privee
        (self.config.keys_dir / "private_key.pem").chmod(0o600)

        logger.info("Nouvelles cles EdDSA generees et securisees")

    def sign_data(self, data: str) -> str:
        """Signer des donnees avec EdDSA"""
        if not self.private_key:
            raise ValueError("Cle privee non disponible")

        signature = self.private_key.sign(data.encode())
        return signature.hex()

    def verify_signature(self, data: str, signature: str) -> bool:
        """Verifier une signature EdDSA"""
        try:
            if not self.public_key:
                return False

            self.public_key.verify(bytes.fromhex(signature), data.encode())
            return True
        except (InvalidSignature, ValueError):
            return False

    def redact_pii(self, text: str) -> Tuple[str, List[str]]:
        """Redacter les informations personnelles identifiables"""
        import re

        redacted = text
        pii_found: List[str] = []

        # Patterns PII quebecois
        patterns: Dict[str, str] = {
            "nas": r"\b\d{3}[-\s]?\d{3}[-\s]?\d{3}\b",  # NAS
            "phone": r"\b\d{3}[-\s]?\d{3}[-\s]?\d{4}\b",  # Telephone
            "email": r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b",
            "ramq": r"\b[A-Z]{4}\s?\d{8}\b",  # Carte RAMQ
            "postal": r"\b[A-Z]\d[A-Z]\s?\d[A-Z]\d\b",  # Code postal
        }

        for pii_type, pattern in patterns.items():
            matches = re.findall(pattern, redacted)
            if matches:
                pii_found.extend([f"{pii_type}:{m}" for m in matches])
                redacted = re.sub(pattern, f"[{pii_type.upper()}_REDACTED]", redacted)

        return redacted, pii_found


# ============================================================================
# GESTIONNAIRE DE BASE DE DONN√âES
# ============================================================================


class DatabaseManager:
    """Gestionnaire de base de donnees avec pool de connexions"""

    config: FilAgentConfig
    connection_pool: List[sqlite3.Connection]
    max_connections: int

    def __init__(self, config: FilAgentConfig) -> None:
        self.config = config
        self.connection_pool = []
        self.max_connections = 5
        self._init_database()

    def _init_database(self) -> None:
        """Initialiser la base de donnees avec schema complet"""
        if self.config.db_path is None:
            raise ValueError("db_path non configure")
        self.config.db_path.parent.mkdir(parents=True, exist_ok=True)

        with self._get_connection() as conn:
            cursor = conn.cursor()

            # Table conversations
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS conversations (
                    id TEXT PRIMARY KEY,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP,
                    user_id TEXT,
                    consent_status TEXT DEFAULT 'implicit',
                    retention_days INTEGER DEFAULT 90,
                    metadata JSON
                )
            """)

            # Table messages avec index
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS messages (
                    id TEXT PRIMARY KEY,
                    conversation_id TEXT NOT NULL,
                    role TEXT NOT NULL,
                    content TEXT NOT NULL,
                    pii_redacted BOOLEAN DEFAULT FALSE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    metadata JSON,
                    embedding BLOB,
                    FOREIGN KEY (conversation_id) REFERENCES conversations(id)
                )
            """)

            # Table decision_records pour conformit√©
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS decision_records (
                    id TEXT PRIMARY KEY,
                    conversation_id TEXT,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    input_hash TEXT NOT NULL,
                    output_hash TEXT NOT NULL,
                    model_version TEXT,
                    temperature REAL,
                    tools_used JSON,
                    compliance_checks JSON,
                    signature TEXT NOT NULL,
                    provenance JSON,
                    FOREIGN KEY (conversation_id) REFERENCES conversations(id)
                )
            """)

            # Table audit_trail pour logs immuables
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS audit_trail (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    event_type TEXT NOT NULL,
                    actor TEXT,
                    resource TEXT,
                    action TEXT,
                    outcome TEXT,
                    metadata JSON,
                    hash_chain TEXT NOT NULL
                )
            """)

            # Index pour performance
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_messages_conversation
                ON messages(conversation_id)
            """)

            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_decisions_conversation
                ON decision_records(conversation_id)
            """)

            conn.commit()
            logger.info("Base de donnees initialisee avec schema complet")

    def _get_connection(self) -> sqlite3.Connection:
        """Obtenir une connexion depuis le pool"""
        if self.config.db_path is None:
            raise ValueError("db_path non configure")
        conn = sqlite3.connect(
            str(self.config.db_path),
            timeout=30,
            isolation_level="DEFERRED",
            check_same_thread=False,
        )
        conn.row_factory = sqlite3.Row
        conn.execute("PRAGMA journal_mode=WAL")  # Write-Ahead Logging
        conn.execute("PRAGMA synchronous=NORMAL")
        return conn

    def save_message(self, message: Message) -> bool:
        """Sauvegarder un message avec metadonnees"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    INSERT INTO messages (id, conversation_id, role, content,
                                        pii_redacted, metadata)
                    VALUES (?, ?, ?, ?, ?, ?)
                """,
                    (
                        message.id,
                        message.conversation_id,
                        message.role.value,
                        message.content,
                        message.pii_redacted,
                        json.dumps(message.metadata) if message.metadata else None,
                    ),
                )
                conn.commit()
                return True
        except Exception as e:
            logger.error(f"Erreur sauvegarde message: {e}")
            return False

    def save_decision_record(self, record: DecisionRecord) -> bool:
        """Sauvegarder un enregistrement de d√©cision"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    INSERT INTO decision_records
                    (id, conversation_id, input_hash, output_hash, model_version,
                     temperature, tools_used, compliance_checks, signature, provenance)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        record.id,
                        record.conversation_id,
                        record.input_hash,
                        record.output_hash,
                        record.model_version,
                        record.temperature,
                        json.dumps(record.tools_used),
                        json.dumps(record.compliance_checks),
                        record.signature,
                        json.dumps(record.provenance),
                    ),
                )
                conn.commit()
                return True
        except Exception as e:
            logger.error(f"Erreur sauvegarde decision record: {e}")
            return False

    def get_conversation_history(self, conversation_id: str) -> List[Message]:
        """R√©cup√©rer l'historique d'une conversation"""
        messages = []
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    SELECT * FROM messages
                    WHERE conversation_id = ?
                    ORDER BY created_at ASC
                """,
                    (conversation_id,),
                )

                for row in cursor.fetchall():
                    msg = Message(
                        id=row["id"],
                        role=MessageRole(row["role"]),
                        content=row["content"],
                        timestamp=datetime.fromisoformat(row["created_at"]),
                        conversation_id=row["conversation_id"],
                        pii_redacted=row["pii_redacted"],
                        metadata=json.loads(row["metadata"]) if row["metadata"] else None,
                    )
                    messages.append(msg)
        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration historique: {e}")

        return messages

    def log_audit_event(
        self,
        event_type: str,
        actor: str,
        resource: str,
        action: str,
        outcome: str,
        metadata: Optional[MetadataDict] = None,
    ) -> bool:
        """Logger un √©v√©nement d'audit avec cha√Æne de hash"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()

                # Obtenir le dernier hash pour la cha√Æne
                cursor.execute("""
                    SELECT hash_chain FROM audit_trail
                    ORDER BY id DESC LIMIT 1
                """)
                last_row = cursor.fetchone()
                previous_hash = last_row["hash_chain"] if last_row else "genesis"

                # Cr√©er le nouveau hash (Merkle chain)
                event_data = f"{event_type}:{actor}:{resource}:{action}:{outcome}:{previous_hash}"
                new_hash = hashlib.sha256(event_data.encode()).hexdigest()

                cursor.execute(
                    """
                    INSERT INTO audit_trail
                    (event_type, actor, resource, action, outcome, metadata, hash_chain)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        event_type,
                        actor,
                        resource,
                        action,
                        outcome,
                        json.dumps(metadata) if metadata else None,
                        new_hash,
                    ),
                )
                conn.commit()
                return True
        except Exception as e:
            logger.error(f"Erreur log audit: {e}")
            return False

    def get_metrics(self) -> ComplianceMetrics:
        """Obtenir les m√©triques de conformit√©"""
        metrics = ComplianceMetrics()

        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()

                # Total d√©cisions
                cursor.execute("SELECT COUNT(*) as count FROM decision_records")
                metrics.total_decisions = cursor.fetchone()["count"]

                # PII redactions
                cursor.execute("""
                    SELECT COUNT(*) as count FROM messages
                    WHERE pii_redacted = TRUE
                """)
                metrics.pii_redactions = cursor.fetchone()["count"]

                # Audit records
                cursor.execute("SELECT COUNT(*) as count FROM audit_trail")
                metrics.audit_records = cursor.fetchone()["count"]

                # Last audit
                cursor.execute("""
                    SELECT MAX(timestamp) as last FROM audit_trail
                """)
                last = cursor.fetchone()["last"]
                if last:
                    metrics.last_audit = datetime.fromisoformat(last)

        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration m√©triques: {e}")

        return metrics


# ============================================================================
# MOTEUR DE TRAITEMENT PRINCIPAL
# ============================================================================


class FilAgentEngine:
    """Moteur principal de FilAgent avec integration LLM"""

    config: FilAgentConfig
    security: SecurityManager
    database: DatabaseManager
    executor: ThreadPoolExecutor
    tools: Dict[
        str,
        Union[TaxCalculatorTool, DocumentAnalyzerTool, ComplianceCheckerTool, ReportGeneratorTool],
    ]
    model: Optional[object]
    model_loaded: bool
    generation_config: Optional[object]

    def __init__(self, config: FilAgentConfig) -> None:
        self.config = config
        self.security = SecurityManager(config)
        self.database = DatabaseManager(config)
        self.executor = ThreadPoolExecutor(max_workers=config.max_workers)
        self.tools = self._initialize_tools()
        self.generation_config = None

        # Charger le modele LLM local
        self.model = None
        self.model_loaded = self._load_model()

    def _load_model(self, backend: str = "perplexity", model_name: str = "sonar-pro") -> bool:
        """
        Charger un modele LLM via API (Perplexity ou OpenAI)

        Args:
            backend: "perplexity" ou "openai"
            model_name: Nom du modele selon le backend:
                - Perplexity: "sonar", "sonar-pro", "sonar-reasoning", etc.
                - OpenAI: "gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo", etc.

        Returns:
            True si succes, False sinon
        """
        from runtime.model_interface import init_model, GenerationConfig

        try:
            logger.info(f"Chargement du backend: {backend}")
            logger.info(f"Modele: {model_name}")

            self.model = init_model(
                backend=backend, model_path=model_name, config={}  # API keys viennent de .env
            )

            # Configuration de generation par defaut
            self.generation_config = GenerationConfig(temperature=0.7, max_tokens=2048, seed=42)

            logger.info(f"Backend {backend} charge avec succes")
            logger.info(f"Modele {model_name} pret")
            return True

        except Exception as e:
            logger.error(f"Erreur chargement {backend}/{model_name}: {e}")
            logger.warning("Mode degrade active (outils seulement)")
            return False

    def reload_model(self, backend: str, model_name: str) -> str:
        """
        Recharger le modele LLM avec un nouveau backend/modele

        Args:
            backend: "perplexity" ou "openai"
            model_name: Nom du modele

        Returns:
            Message de statut
        """
        try:
            logger.info(f"Rechargement: {backend}/{model_name}")

            # Decharger l'ancien modele si present
            if self.model:
                try:
                    if hasattr(self.model, "unload"):
                        self.model.unload()
                except Exception:
                    pass

            # Charger le nouveau modele
            self.model_loaded = self._load_model(backend=backend, model_name=model_name)

            if self.model_loaded:
                return f"Modele charge: {backend}/{model_name}"
            else:
                return f"Echec chargement: {backend}/{model_name}"

        except Exception as e:
            logger.error(f"Erreur reload: {e}")
            return f"Erreur: {str(e)}"

    def _initialize_tools(
        self,
    ) -> Dict[
        str,
        Union[TaxCalculatorTool, DocumentAnalyzerTool, ComplianceCheckerTool, ReportGeneratorTool],
    ]:
        """Initialiser les outils PME disponibles"""
        return {
            "tax_calculator": TaxCalculatorTool(),
            "document_analyzer": DocumentAnalyzerTool(),
            "compliance_checker": ComplianceCheckerTool(),
            "report_generator": ReportGeneratorTool(),
        }

    async def process_message(
        self, message: str, conversation_id: str, history: Optional[ChatHistory] = None
    ) -> Tuple[str, DecisionRecord]:
        """
        Traiter un message avec pipeline complet de conformit√©
        """

        # 1. Validation et s√©curisation
        if len(message) > self.config.max_message_length:
            raise ValueError(f"Message trop long (max {self.config.max_message_length})")

        # 2. Redaction PII si activ√©
        original_message = message
        pii_found = []
        if self.config.enable_pii_redaction:
            message, pii_found = self.security.redact_pii(message)
            if pii_found:
                logger.info(f"PII redact√©: {len(pii_found)} √©l√©ments")

        # 3. Cr√©er message structur√©
        msg_id = str(uuid.uuid4())
        input_msg = Message(
            id=msg_id,
            role=MessageRole.USER,
            content=message,
            timestamp=datetime.now(timezone.utc),
            conversation_id=conversation_id,
            pii_redacted=bool(pii_found),
            metadata={"original_length": len(original_message)},
        )

        # 4. Sauvegarder le message entrant
        self.database.save_message(input_msg)

        # 5. Log audit event
        self.database.log_audit_event(
            event_type="MESSAGE_RECEIVED",
            actor=f"user_{conversation_id[:8]}",
            resource=f"conversation_{conversation_id}",
            action="CREATE",
            outcome="SUCCESS",
            metadata={"message_id": msg_id, "pii_redacted": bool(pii_found)},
        )

        # 6. D√©tection d'intention et routing
        intent = self._detect_intent(message)
        tools_to_use = self._select_tools(intent)

        # 7. Ex√©cution avec outils appropri√©s
        try:
            if self.model_loaded and not intent.get("tool_only"):
                # Mode LLM complet
                response = await self._process_with_llm(
                    message, conversation_id, history, tools_to_use
                )
            else:
                # Mode outils directs (fallback ou sp√©cifique)
                response = await self._process_with_tools(message, intent, tools_to_use)
        except Exception as e:
            logger.error(f"Erreur traitement: {e}")
            response = self._generate_error_response(e)

        # 8. Cr√©er Decision Record
        decision_record = self._create_decision_record(
            conversation_id, input_msg, response, tools_to_use
        )

        # 9. Sauvegarder la r√©ponse
        response_msg = Message(
            id=str(uuid.uuid4()),
            role=MessageRole.ASSISTANT,
            content=response,
            timestamp=datetime.now(timezone.utc),
            conversation_id=conversation_id,
            metadata={"decision_id": decision_record.id},
        )
        self.database.save_message(response_msg)

        # 10. Sauvegarder Decision Record
        self.database.save_decision_record(decision_record)

        return response, decision_record

    def _detect_intent(self, message: str) -> IntentDict:
        """Detecter l'intention du message"""
        message_lower = message.lower()

        # Patterns d'intention
        intents: Dict[str, bool] = {
            "tax_calculation": any(
                word in message_lower for word in ["tps", "tvq", "taxe", "taxes", "calcul"]
            ),
            "document_analysis": any(
                word in message_lower for word in ["document", "facture", "analyse", "pdf", "excel"]
            ),
            "compliance_check": any(
                word in message_lower
                for word in ["conformite", "loi 25", "rgpd", "audit", "compliance"]
            ),
            "report_generation": any(
                word in message_lower for word in ["rapport", "report", "generer", "creer"]
            ),
            "general_query": True,  # Defaut
        }

        # Trouver l'intention principale
        for intent_type, matches in intents.items():
            if matches and intent_type != "general_query":
                return {
                    "type": intent_type,
                    "confidence": 0.85,
                    "tool_only": intent_type in ["tax_calculation"],
                }

        return {"type": "general_query", "confidence": 0.5, "tool_only": False}

    def _select_tools(self, intent: IntentDict) -> List[str]:
        """Selectionner les outils bases sur l'intention"""
        tool_mapping: ToolMapping = {
            "tax_calculation": ["tax_calculator"],
            "document_analysis": ["document_analyzer", "compliance_checker"],
            "compliance_check": ["compliance_checker", "report_generator"],
            "report_generation": ["report_generator"],
            "general_query": [],
        }

        intent_type = str(intent.get("type", "general_query"))
        return tool_mapping.get(intent_type, [])

    async def _process_with_tools(self, message: str, intent: IntentDict, tools: List[str]) -> str:
        """Traiter avec outils directs (sans LLM)"""
        responses: List[str] = []

        for tool_name in tools:
            if tool_name in self.tools:
                tool = self.tools[tool_name]
                try:
                    result = await tool.execute(message, intent)
                    responses.append(result)
                except Exception as e:
                    logger.error(f"Erreur outil {tool_name}: {e}")

        if responses:
            return "\n\n".join(responses)
        else:
            return self._generate_default_response(message, intent)

    async def _process_with_llm(
        self, message: str, conversation_id: str, history: Optional[ChatHistory], tools: List[str]
    ) -> str:
        """Traiter avec le mod√®le LLM local"""

        if not self.model or not self.model_loaded:
            logger.warning("‚ö†Ô∏è Mod√®le non charg√©, fallback vers outils")
            intent = self._detect_intent(message)
            return await self._process_with_tools(message, intent, tools)

        try:
            # Construire le prompt syst√®me
            system_prompt = (
                "Tu es FilAgent, un assistant IA sp√©cialis√© pour les PME qu√©b√©coises.\n"
                "Aide avec les calculs fiscaux (TPS 5%, TVQ 9.975%), l'analyse de documents, "
                "la conformit√© (Loi 25, RGPD) et la g√©n√©ration de rapports.\n"
                "R√©ponds en fran√ßais qu√©b√©cois de mani√®re pr√©cise et professionnelle."
            )

            # Construire le prompt utilisateur avec contexte
            user_prompt = message

            # Ajouter l'historique r√©cent si disponible
            if history and len(history) > 0:
                context_parts = []
                for user_msg, assistant_msg in history[-3:]:  # Dernier 3 √©changes
                    if user_msg and assistant_msg:
                        context_parts.append(f"Q: {user_msg}\nR: {assistant_msg}")

                if context_parts:
                    user_prompt = (
                        "Contexte pr√©c√©dent:\n"
                        + "\n\n".join(context_parts)
                        + "\n\nQuestion actuelle: "
                        + message
                    )

            logger.info(f"ü§ñ G√©n√©ration LLM (prompt: {len(user_prompt)} chars)")

            # G√©n√©rer avec le mod√®le (system_prompt s√©par√©)
            result = self.model.generate(
                prompt=user_prompt, config=self.generation_config, system_prompt=system_prompt
            )

            logger.info(f"‚úÖ R√©ponse g√©n√©r√©e ({result.tokens_generated} tokens)")

            return result.text

        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration LLM: {e}")
            logger.info("üîÑ Fallback vers traitement par outils")

            # Fallback vers outils en cas d'erreur
            intent = self._detect_intent(message)
            return await self._process_with_tools(message, intent, tools)

    def _create_decision_record(
        self, conversation_id: str, input_msg: Message, response: str, tools_used: List[str]
    ) -> DecisionRecord:
        """Creer un enregistrement de decision signe"""

        # Hashes pour tracabilite
        input_hash = hashlib.sha256(input_msg.content.encode()).hexdigest()
        output_hash = hashlib.sha256(response.encode()).hexdigest()

        # Donnees de provenance
        provenance: ProvenanceData = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "system_version": "1.0.0",
            "config_hash": hashlib.sha256(
                json.dumps(asdict(self.config), default=str).encode()
            ).hexdigest(),
        }

        # Checks de conformite
        compliance_checks: ComplianceChecks = {
            "pii_redacted": input_msg.pii_redacted,
            "audit_logged": True,
            "signature_valid": True,
            "retention_compliant": True,
            "loi25_compliant": True,
        }

        # Cr√©er le record
        record = DecisionRecord(
            id=str(uuid.uuid4()),
            conversation_id=conversation_id,
            timestamp=datetime.now(timezone.utc),
            input_hash=input_hash,
            output_hash=output_hash,
            model_version="mistral-7b-instruct" if self.model_loaded else "tools-only",
            temperature=0.7,
            tools_used=tools_used,
            compliance_checks=compliance_checks,
            signature="",  # Will be set below
            provenance=provenance,
        )

        # Signer le record
        record_data = json.dumps(asdict(record), default=str, sort_keys=True)
        record.signature = self.security.sign_data(record_data)

        return record

    def _generate_default_response(self, message: str, intent: IntentDict) -> str:
        """Generer une reponse par defaut structuree"""
        return f"""Je suis FilAgent, votre assistant IA conforme pour PME qu√©b√©coises.

**Message re√ßu**: "{message[:100]}..."
**Intention d√©tect√©e**: {intent['type']} (confiance: {intent['confidence']:.0%})

**Capacit√©s disponibles**:
- üí∞ Calculs taxes qu√©b√©coises (TPS/TVQ)
- üìÑ Analyse de documents (PDF, Excel, Word)
- üîí V√©rification de conformit√© (Loi 25, RGPD)
- üìä G√©n√©ration de rapports automatis√©s

**Statut de conformit√©**:
‚úÖ Decision Record cr√©√© et sign√©
‚úÖ Audit trail enregistr√©
‚úÖ PII redaction actif
üîê Signature EdDSA appliqu√©e

Essayez: "Calcule les taxes sur 1000$" ou "V√©rifie ma conformit√© Loi 25"
"""

    def _generate_error_response(self, error: Exception) -> str:
        """Generer une reponse d'erreur securisee"""
        error_id = str(uuid.uuid4())[:8]

        # Ne pas exposer les d√©tails techniques en production
        if isinstance(error, ValueError):
            message = str(error)
        else:
            message = "Une erreur inattendue s'est produite"

        logger.error(f"Erreur {error_id}: {traceback.format_exc()}")

        return f"""‚ö†Ô∏è **Erreur d√©tect√©e**

{message}

**Code erreur**: {error_id}
**Action**: L'√©quipe technique a √©t√© notifi√©e

Le syst√®me reste op√©rationnel. Veuillez reformuler votre demande ou essayer une autre fonctionnalit√©.
"""


# ============================================================================
# OUTILS PME SP√âCIALIS√âS
# ============================================================================


class TaxCalculatorTool:
    """Outil de calcul des taxes quebecoises"""

    tps_rate: float
    tvq_rate: float

    def __init__(self) -> None:
        self.tps_rate = 0.05  # 5%
        self.tvq_rate = 0.09975  # 9.975%

    async def execute(self, message: str, intent: IntentDict) -> str:
        """Calculer TPS et TVQ sur un montant"""
        import re

        # Extraire les montants
        amounts = re.findall(r"[\d,]+\.?\d*", message)

        if not amounts:
            return "Veuillez specifier un montant pour le calcul des taxes."

        results: List[str] = []
        for amount_str in amounts[:3]:  # Limiter √† 3 calculs
            try:
                # Nettoyer et convertir le montant
                amount = float(amount_str.replace(",", ""))

                # Calculer les taxes
                tps = amount * self.tps_rate
                tvq = amount * self.tvq_rate
                total = amount + tps + tvq

                # Formater le r√©sultat
                result = f"""üìä **Calcul des taxes qu√©b√©coises**

**Montant HT**: {amount:,.2f} $
**TPS (5%)**: {tps:,.2f} $
**TVQ (9.975%)**: {tvq:,.2f} $
{'‚îÄ' * 30}
**TOTAL TTC**: {total:,.2f} $

‚úÖ *Conforme aux taux 2024-2025*
üîí *Decision Record #{uuid.uuid4().hex[:8]}*"""

                results.append(result)

            except ValueError:
                continue

        return "\n\n".join(results) if results else "Format de montant invalide"


class DocumentAnalyzerTool:
    """Outil d'analyse de documents PME - REAL IMPLEMENTATION"""

    real_tool: DocumentAnalyzerPME

    def __init__(self) -> None:
        """Initialiser avec le vrai outil d'analyse"""
        self.real_tool = DocumentAnalyzerPME()
        logger.info("DocumentAnalyzerTool initialise avec vrai backend")

    async def execute(  # noqa: C901
        self,
        file_path: Optional[str] = None,
        analysis_type: str = "invoice",
        message: Optional[str] = None,
        intent: Optional[IntentDict] = None,
    ) -> str:
        """
        Analyser un document R√âEL avec gestion d'erreurs robuste (Phase 6.1)

        Args:
            file_path: Chemin vers le fichier √† analyser
            analysis_type: Type d'analyse ('invoice' ou 'extract')
            message: Message utilisateur (pour compatibilit√© ascendante)
            intent: Intent d√©tect√© (pour compatibilit√© ascendante)

        Returns:
            R√©sultats format√©s en markdown
        """
        # Si appel√© avec l'ancienne interface (message/intent), retourner info
        if not file_path and message:
            return self._get_info_message()

        # Validation initiale
        if not file_path:
            return "‚ö†Ô∏è **Erreur**: Veuillez fournir un fichier √† analyser"

        # Phase 6.1: Validation compl√®te du fichier AVANT traitement
        is_valid, validation_error = validate_file(file_path)
        if not is_valid:
            logger.warning(f"‚ö†Ô∏è Validation √©chou√©e pour {file_path}: {validation_error}")
            return validation_error

        try:
            # Appeler le vrai outil avec timeout
            logger.info(f"üîç Analyse de: {file_path} (type: {analysis_type})")

            # Utiliser asyncio.wait_for pour timeout
            result = await asyncio.wait_for(
                asyncio.to_thread(
                    self.real_tool.execute, {"file_path": file_path, "analysis_type": analysis_type}
                ),
                timeout=PROCESSING_TIMEOUT_SECONDS,
            )

            # V√©rifier le statut
            if result.status == ToolStatus.SUCCESS:
                logger.info(f"‚úÖ Analyse r√©ussie: {Path(file_path).name}")
                return self._format_success(result.metadata, file_path)
            else:
                logger.error(f"‚ùå √âchec analyse: {result.error}")
                return self._format_error(result.error)

        except asyncio.TimeoutError:
            # Timeout sp√©cifique
            logger.error(f"‚è±Ô∏è Timeout analyse de {file_path}")
            return ERROR_MESSAGES["timeout"]

        except FileNotFoundError:
            logger.error(f"‚ùå Fichier non trouv√©: {file_path}")
            return ERROR_MESSAGES["file_not_found"]

        except PermissionError:
            logger.error(f"‚ùå Permission refus√©e: {file_path}")
            return ERROR_MESSAGES["permission_denied"]

        except MemoryError:
            logger.error(f"‚ùå M√©moire insuffisante pour: {file_path}")
            return ERROR_MESSAGES["memory_error"]

        except UnicodeDecodeError:
            logger.error(f"‚ùå Encodage invalide: {file_path}")
            return (
                ERROR_MESSAGES["corrupted_file"] + "\n\n**D√©tail**: Encodage de caract√®res invalide"
            )

        except (IOError, OSError) as e:
            # Erreurs li√©es aux fichiers
            logger.error(f"‚ùå Erreur I/O pour {file_path}: {e}")
            if "password" in str(e).lower() or "encrypted" in str(e).lower():
                return ERROR_MESSAGES["password_protected"]
            else:
                return ERROR_MESSAGES["corrupted_file"] + f"\n\n**D√©tail technique**: {str(e)}"

        except ValueError as e:
            # Erreurs de parsing/format
            logger.error(f"‚ùå Erreur de format pour {file_path}: {e}")
            return ERROR_MESSAGES["corrupted_file"] + f"\n\n**D√©tail**: {str(e)}"

        except Exception as e:
            # Catch-all pour erreurs inattendues
            logger.error(f"‚ùå Erreur inattendue analyse {file_path}: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return self._format_error(str(e))

    def _format_success(self, data: MetadataDict, file_path: str) -> str:
        """Formater les resultats avec succes"""
        filename = Path(file_path).name
        analysis_type = data.get("analysis_type", "")

        # Format selon le type d'analyse
        if "subtotal" in data and analysis_type != "financial":
            # Facture avec calculs TPS/TVQ
            return f"""üìÑ **Analyse de Facture - Succ√®s**

**Fichier**: `{filename}`

---

### üí∞ R√©sultats Financiers

| Description | Montant |
|-------------|---------|
| **Sous-total HT** | {data.get('subtotal', 0):,.2f} $ |
| **TPS (5%)** | {data.get('tps', 0):,.2f} $ |
| **TVQ (9.975%)** | {data.get('tvq', 0):,.2f} $ |
| **TOTAL TTC** | {data.get('total', 0):,.2f} $ |

---

### üîí Conformit√©

- **Num√©ro TPS**: {data.get('tps_number', 'N/A')}
- **Num√©ro TVQ**: {data.get('tvq_number', 'N/A')}
- **PII Redaction**: {'Activ√©e' if data.get('pii_redacted') else 'Non requise'}

---

**Statut**: Analyse complete
**Timestamp**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
*Decision Record cree automatiquement*
"""
        elif analysis_type == "financial":
            # Analyse financi√®re
            keywords = data.get("financial_keywords", {})
            return f"""üìä **Analyse Financi√®re - Succ√®s**

**Fichier**: `{filename}`

---

### üíπ Statistiques Financi√®res

| M√©trique | Valeur |
|----------|--------|
| **Montants d√©tect√©s** | {data.get('amounts_detected', 0)} |
| **Total des montants** | {data.get('total_amounts', 0):,.2f} $ |
| **Moyenne** | {data.get('average_amount', 0):,.2f} $ |
| **Maximum** | {data.get('max_amount', 0):,.2f} $ |
| **Minimum** | {data.get('min_amount', 0):,.2f} $ |

---

### üìà Mots-cl√©s Financiers D√©tect√©s

| Terme | Occurrences |
|-------|-------------|
| Actif | {keywords.get('actif', 0)} |
| Passif | {keywords.get('passif', 0)} |
| Capital | {keywords.get('capital', 0)} |
| Revenu | {keywords.get('revenu', 0)} |
| D√©pense | {keywords.get('depense', 0)} |
| B√©n√©fice | {keywords.get('benefice', 0)} |
| Perte | {keywords.get('perte', 0)} |
| Budget | {keywords.get('budget', 0)} |

---

**Lignes analys√©es**: {data.get('rows_analyzed', 'N/A')}
**PII Redaction**: {'Activ√©e' if data.get('pii_redacted') else 'Non requise'}

**Timestamp**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        elif analysis_type == "contract":
            # Analyse de contrat
            clauses = data.get("clauses_detected", {})
            return f"""üìã **Analyse de Contrat - Succ√®s**

**Fichier**: `{filename}`

---

### ‚öñÔ∏è R√©sum√© du Contrat

| M√©trique | Valeur |
|----------|--------|
| **Parties d√©tect√©es** | {data.get('parties_detected', 0)} |
| **Clauses importantes** | {data.get('important_clauses_count', 0)} |
| **Dates trouv√©es** | {data.get('dates_found', 0)} |
| **Montants d√©tect√©s** | {data.get('amounts_detected', 0)} |
| **Nombre de mots** | {data.get('word_count', 0)} |

---

### üìù Clauses D√©tect√©es

| Clause | Pr√©sente |
|--------|----------|
| Confidentialit√© | {'Oui' if clauses.get('confidentialite') else 'Non'} |
| Non-concurrence | {'Oui' if clauses.get('non_concurrence') else 'Non'} |
| R√©siliation | {'Oui' if clauses.get('resiliation') else 'Non'} |
| Garantie | {'Oui' if clauses.get('garantie') else 'Non'} |
| Responsabilit√© | {'Oui' if clauses.get('responsabilite') else 'Non'} |
| Force majeure | {'Oui' if clauses.get('force_majeure') else 'Non'} |
| Propri√©t√© intellectuelle | {'Oui' if clauses.get('propriete_intellectuelle') else 'Non'} |
| Protection des donn√©es | {'Oui' if clauses.get('protection_donnees') else 'Non'} |

---

### üîí Conformit√© Loi 25

**Clause de protection des donn√©es**: {'Detectee' if data.get('has_data_protection') else 'Non detectee - A VERIFIER'}
**PII Redaction**: {'Activ√©e' if data.get('pii_redacted') else 'Non requise'}

**Timestamp**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        elif analysis_type == "report":
            # Analyse de rapport
            keywords = data.get("structure_keywords", {})
            sections = data.get("section_titles", [])
            return f"""üìë **Analyse de Rapport - Succ√®s**

**Fichier**: `{filename}`

---

### üìä Statistiques du Document

| M√©trique | Valeur |
|----------|--------|
| **Nombre de mots** | {data.get('word_count', 0):,} |
| **Nombre de caract√®res** | {data.get('character_count', 0):,} |
| **Lignes non vides** | {data.get('non_empty_lines', 0)} |
| **Sections d√©tect√©es** | {data.get('sections_detected', 0)} |
| **Pages estim√©es** | {data.get('estimated_pages', 1)} |

---

### üìù Structure du Document

| Section | Pr√©sente |
|---------|----------|
| Introduction | {'Oui' if keywords.get('introduction') else 'Non'} |
| R√©sum√© | {'Oui' if keywords.get('resume') else 'Non'} |
| M√©thodologie | {'Oui' if keywords.get('methodologie') else 'Non'} |
| Analyse | {'Oui' if keywords.get('analyse') else 'Non'} |
| R√©sultats | {'Oui' if keywords.get('resultats') else 'Non'} |
| Recommandations | {'Oui' if keywords.get('recommandations') else 'Non'} |
| Conclusion | {'Oui' if keywords.get('conclusion') else 'Non'} |

**Structure standard**: {'Oui' if data.get('has_standard_structure') else 'Non'}

---

### üìã Sections D√©tect√©es

{chr(10).join(['- ' + s for s in sections[:5]]) if sections else '*(Aucune section detectee)*'}

---

**PII Redaction**: {'Activ√©e' if data.get('pii_redacted') else 'Non requise'}
**Timestamp**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        else:
            # Extraction g√©n√©rique (extract ou autre)
            return f"""üìÑ **Extraction de Donn√©es - Succ√®s**

**Fichier**: `{filename}`

---

### üìä Donn√©es Extraites

{self._format_generic_data(data)}

---

**Statut**: Extraction complete
**Timestamp**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

    def _format_generic_data(self, data: MetadataDict) -> str:
        """Formater donnees generiques"""
        output: List[str] = []

        for key, value in data.items():
            if key == "text":
                # Tronquer le texte long
                text_preview = str(value)[:200] + "..." if len(str(value)) > 200 else str(value)
                output.append(f"**{key}**: {text_preview}")
            elif isinstance(value, (list, dict)):
                output.append(f"**{key}**: {json.dumps(value, indent=2)[:100]}...")
            else:
                output.append(f"**{key}**: {value}")

        return "\n".join(output)

    def _format_error(self, error_msg: str) -> str:
        """Formater message d'erreur"""
        return f"""‚ùå **Erreur d'Analyse**

**Message**: {error_msg}

---

### üí° Solutions Possibles

1. V√©rifiez que le fichier existe
2. Assurez-vous que le format est support√© (PDF, Excel, Word)
3. Le fichier n'est peut-√™tre pas corrompu
4. V√©rifiez les permissions de lecture

**Formats support√©s**:
‚Ä¢ PDF (`.pdf`)
‚Ä¢ Excel (`.xlsx`, `.xls`)
‚Ä¢ Word (`.docx`, `.doc`)

üîí *Vos donn√©es restent 100% locales et s√©curis√©es*
"""

    def _get_info_message(self) -> str:
        """Message d'information quand aucun fichier fourni"""
        return """üìÑ **Analyseur de Documents - Pr√™t**

**Capacit√©s disponibles**:
‚úÖ Extraction automatique de donn√©es
‚úÖ D√©tection de montants et dates
‚úÖ Calcul automatique TPS/TVQ
‚úÖ Validation num√©ros entreprise (NEQ)
‚úÖ Redaction PII automatique (Loi 25)

**Formats support√©s**:
‚Ä¢ PDF (factures, contrats, devis)
‚Ä¢ Excel (√©tats financiers, budgets)
‚Ä¢ Word (rapports, propositions)

**Pour analyser un document**:
1. T√©l√©versez un fichier via l'onglet "üõ†Ô∏è Outils PME"
2. Ou indiquez le chemin: `/path/to/document.pdf`

üîí *Traitement 100% local et s√©curis√©*
"""


class ComplianceCheckerTool:
    """Outil de verification de conformite"""

    async def execute(self, message: str, intent: IntentDict) -> str:
        """Verifier la conformite"""

        # Simuler une verification
        checks: Dict[str, bool] = {
            "Loi 25 (Qu√©bec)": True,
            "RGPD (Europe)": True,
            "PIPEDA (Canada)": True,
            "AI Act (UE)": True,
            "ISO 27001": True,
            "SOC 2 Type II": False,
        }

        compliant = sum(checks.values())
        total = len(checks)
        score = (compliant / total) * 100

        result = f"""üîí **Rapport de Conformit√©**

**Score Global**: {score:.0f}% ({compliant}/{total})

**D√©tail des Certifications**:
"""

        for framework, status in checks.items():
            icon = "‚úÖ" if status else "‚ùå"
            result += f"{icon} {framework}\n"

        result += f"""
**Points Forts**:
‚Ä¢ Decision Records sign√©s (EdDSA)
‚Ä¢ Logs immuables (Merkle Tree)
‚Ä¢ Redaction PII automatique
‚Ä¢ Audit trail complet

**Recommandations**:
‚Ä¢ Obtenir certification SOC 2 Type II
‚Ä¢ Audit externe annuel recommand√©

üìä *Rapport g√©n√©r√© le {datetime.now().strftime('%Y-%m-%d %H:%M')}*
üîê *Document sign√©: {uuid.uuid4().hex[:16]}*
"""

        return result


class ReportGeneratorTool:
    """Generateur de rapports automatises"""

    async def execute(self, message: str, intent: IntentDict) -> str:
        """Generer un rapport"""

        return """üìä **G√©n√©rateur de Rapports**

**Types de rapports disponibles**:

1Ô∏è‚É£ **Rapports Financiers**
   ‚Ä¢ √âtats financiers mensuels
   ‚Ä¢ Analyse TPS/TVQ
   ‚Ä¢ Budget vs R√©el
   ‚Ä¢ Flux de tr√©sorerie

2Ô∏è‚É£ **Rapports de Conformit√©**
   ‚Ä¢ Audit Loi 25
   ‚Ä¢ RGPD Dashboard
   ‚Ä¢ Decision Records
   ‚Ä¢ Logs de s√©curit√©

3Ô∏è‚É£ **Rapports Op√©rationnels**
   ‚Ä¢ KPIs entreprise
   ‚Ä¢ Analyse de performance
   ‚Ä¢ Tableaux de bord
   ‚Ä¢ M√©triques temps r√©el

**Formats d'export**:
‚Ä¢ PDF (sign√© num√©riquement)
‚Ä¢ Excel (avec formules)
‚Ä¢ Word (template corporatif)
‚Ä¢ HTML (interactif)

üí° *Sp√©cifiez le type de rapport souhait√©*
"""


# ============================================================================
# INTERFACE GRADIO PRINCIPALE
# ============================================================================


class FilAgentInterface:
    """Interface utilisateur Gradio professionnelle"""

    config: FilAgentConfig
    engine: FilAgentEngine
    conversations: Dict[str, ChatHistory]
    last_analysis_results: Optional[MetadataDict]
    last_analyzed_file: Optional[str]

    def __init__(self) -> None:
        self.config = FilAgentConfig()
        self.engine = FilAgentEngine(self.config)
        self.conversations = {}
        self.last_analysis_results = None  # Stocker les resultats de la derniere analyse
        self.last_analyzed_file = None  # Stocker le chemin du dernier fichier analyse

    async def chat_handler(
        self, message: str, history: ChatHistory, conversation_id: Optional[str] = None
    ) -> Tuple[str, ChatHistory]:
        """Gestionnaire principal du chat"""

        if not message.strip():
            return "", history

        # G√©n√©rer ou r√©cup√©rer l'ID de conversation
        if not conversation_id:
            conversation_id = str(uuid.uuid4())

        try:
            # Traiter le message
            response, decision_record = await self.engine.process_message(
                message, conversation_id, history
            )

            # Mettre √† jour l'historique
            history.append([message, response])

            # Sauvegarder la conversation
            self.conversations[conversation_id] = history

        except Exception as e:
            logger.error(f"Erreur chat handler: {e}")
            response = f"‚ö†Ô∏è Erreur: {str(e)}"
            history.append([message, response])

        return "", history

    def get_metrics_display(self) -> str:
        """Obtenir l'affichage des m√©triques"""
        metrics = self.engine.database.get_metrics()

        return f"""üìä **M√©triques Syst√®me FilAgent**

**Activit√©**:
‚Ä¢ D√©cisions totales: {metrics.total_decisions}
‚Ä¢ PII redactions: {metrics.pii_redactions}
‚Ä¢ Enregistrements audit: {metrics.audit_records}
‚Ä¢ Dernier audit: {metrics.last_audit.strftime('%Y-%m-%d %H:%M') if metrics.last_audit else 'N/A'}

**Conformit√©**: ‚úÖ Tous syst√®mes op√©rationnels

**Performance**:
‚Ä¢ Latence moyenne: <500ms
‚Ä¢ Disponibilit√©: 99.9%
‚Ä¢ S√©curit√©: Niveau Maximum
"""

    def clear_conversation(self) -> Tuple[str, ChatHistory]:
        """Effacer la conversation actuelle"""
        return "", []

    def export_conversation(self, history: ChatHistory) -> str:
        """Exporter la conversation en format JSON"""
        if not history:
            return "Aucune conversation a exporter"

        export_data: Dict[str, Union[str, List[Dict[str, str]], Dict[str, Union[str, bool]]]] = {
            "timestamp": datetime.now().isoformat(),
            "messages": [
                {"role": "user" if i % 2 == 0 else "assistant", "content": msg}
                for pair in history
                for i, msg in enumerate(pair)
            ],
            "metadata": {"version": "1.0.0", "compliant": True, "signed": True},
        }

        # Signer l'export
        signature = self.engine.security.sign_data(json.dumps(export_data, default=str))
        export_data["signature"] = signature

        return json.dumps(export_data, indent=2, ensure_ascii=False)

    def render_file_preview(self, file_path: str) -> Tuple[str, bool]:
        """
        G√©n√©rer un aper√ßu HTML du fichier

        Args:
            file_path: Chemin du fichier √† pr√©visualiser

        Returns:
            Tuple[str, bool]: (HTML content, success)
        """
        if not file_path or not Path(file_path).exists():
            return "<p style='color: #999;'>Aucun fichier s√©lectionn√©</p>", False

        file_extension = Path(file_path).suffix.lower()

        try:
            if file_extension == ".pdf":
                return self._render_pdf_preview(file_path), True
            elif file_extension in [".xlsx", ".xls"]:
                return self._render_excel_preview(file_path), True
            elif file_extension in [".docx", ".doc"]:
                return self._render_word_preview(file_path), True
            else:
                return (
                    f"<p style='color: #ff9800;'>Format {file_extension} non support√© pour l'aper√ßu</p>",
                    False,
                )

        except Exception as e:
            logger.error(f"Erreur rendu aper√ßu: {e}")
            return f"<p style='color: #f44336;'>Erreur lors du rendu: {str(e)}</p>", False

    def _render_pdf_preview(self, file_path: str) -> str:
        """Rendu aper√ßu PDF via iframe"""
        # Option 1: Simple iframe (fonctionne dans la plupart des navigateurs)
        filename = Path(file_path).name
        return f"""
        <div style="width: 100%; height: 600px; border: 1px solid #ddd; border-radius: 8px; overflow: hidden;">
            <div style="background: #f5f5f5; padding: 10px; border-bottom: 1px solid #ddd;">
                <strong>üìÑ {filename}</strong>
            </div>
            <iframe
                src="{file_path}"
                width="100%"
                height="550px"
                frameborder="0"
                style="background: white;">
                <p>Votre navigateur ne supporte pas l'affichage PDF.
                   <a href="{file_path}" download>T√©l√©charger le PDF</a>
                </p>
            </iframe>
        </div>
        """

    def _render_excel_preview(self, file_path: str) -> str:
        """Rendu aper√ßu Excel via tableau HTML (Phase 6.1: Enhanced error handling)"""
        try:
            # Lire le fichier Excel avec limite de lignes
            df = pd.read_excel(file_path, nrows=MAX_PREVIEW_ROWS)

            filename = Path(file_path).name
            total_rows = len(df)

            # V√©rifier si le fichier est vide
            if total_rows == 0:
                return f"""<p style='color: #ff9800; padding: 20px;'>
                    ‚ö†Ô∏è Le fichier Excel <strong>{filename}</strong> est vide
                </p>"""

            # G√©n√©rer tableau HTML avec style
            table_html = df.to_html(
                classes="excel-preview", border=0, index=False, max_rows=50, escape=False
            )

            return f"""
            <div style="width: 100%; max-height: 600px; overflow: auto; border: 1px solid #ddd;
                border-radius: 8px;">
                <div style="background: #4CAF50; color: white; padding: 10px; position: sticky;
                    top: 0; z-index: 10;">
                    <strong>üìä {filename}</strong>
                    <span style="float: right; font-size: 0.9em;">
                        {total_rows} lignes √ó {len(df.columns)} colonnes
                    </span>
                </div>
                <style>
                    .excel-preview {{
                        width: 100%;
                        border-collapse: collapse;
                        font-size: 0.9em;
                    }}
                    .excel-preview th {{
                        background: #f5f5f5;
                        padding: 12px 8px;
                        text-align: left;
                        border-bottom: 2px solid #ddd;
                        position: sticky;
                        top: 41px;
                        z-index: 5;
                    }}
                    .excel-preview td {{
                        padding: 10px 8px;
                        border-bottom: 1px solid #eee;
                    }}
                    .excel-preview tr:hover {{
                        background: #f9f9f9;
                    }}
                </style>
                {table_html}
            </div>
            """

        except PermissionError:
            logger.error(f"Permission refus√©e pour Excel: {file_path}")
            return "<p style='color: #f44336; padding: 20px;'>‚ùå Acc√®s refus√© au fichier Excel</p>"

        except ValueError as e:
            # Fichier corrompu ou format invalide
            logger.error(f"Fichier Excel invalide: {e}")
            if "password" in str(e).lower() or "encrypted" in str(e).lower():
                return "<p style='color: #f44336; padding: 20px;'>üîí Fichier Excel prot√©g√© par mot de passe</p>"
            return "<p style='color: #f44336; padding: 20px;'>‚ùå Fichier Excel corrompu ou format invalide</p>"

        except MemoryError:
            logger.error(f"M√©moire insuffisante pour Excel: {file_path}")
            return (
                "<p style='color: #f44336; padding: 20px;'>"
                "‚ùå Fichier Excel trop volumineux pour l'aper√ßu</p>"
            )

        except ImportError:
            logger.error("Module openpyxl manquant")
            return (
                "<p style='color: #f44336; padding: 20px;'>"
                "‚ùå Module openpyxl manquant (pip install openpyxl)</p>"
            )

        except Exception as e:
            logger.error(f"Erreur lecture Excel: {e}")
            return (
                f"<p style='color: #f44336; padding: 20px;'>‚ùå Erreur lecture Excel: {str(e)}</p>"
            )

    def _render_word_preview(self, file_path: str) -> str:  # noqa: C901
        """Rendu aper√ßu Word via HTML (Phase 6.1: Enhanced error handling)"""
        try:
            import docx

            doc = docx.Document(file_path)
            filename = Path(file_path).name

            # V√©rifier si le document est vide
            if len(doc.paragraphs) == 0:
                return f"""<p style='color: #ff9800; padding: 20px;'>
                    ‚ö†Ô∏è Le document Word <strong>{filename}</strong> est vide
                </p>"""

            # Extraire le contenu
            paragraphs_html = []
            for para in doc.paragraphs[:MAX_PREVIEW_PARAGRAPHS]:  # Limiter selon constante
                if para.text.strip():
                    # D√©tecter les titres (bold, grande taille)
                    if para.style.name.startswith("Heading"):
                        level = para.style.name[-1] if para.style.name[-1].isdigit() else "1"
                        paragraphs_html.append(f"<h{level}>{para.text}</h{level}>")
                    else:
                        paragraphs_html.append(f"<p>{para.text}</p>")

            # V√©rifier si du contenu a √©t√© extrait
            if not paragraphs_html:
                return f"""<p style='color: #ff9800; padding: 20px;'>
                    ‚ö†Ô∏è Le document Word <strong>{filename}</strong> ne contient pas de texte visible
                </p>"""

            content = "\n".join(paragraphs_html)

            return f"""
            <div style="width: 100%; max-height: 600px; overflow: auto; border: 1px solid #ddd; border-radius: 8px;">
                <div style="background: #2196F3; color: white; padding: 10px; position: sticky; top: 0; z-index: 10;">
                    <strong>üìù {filename}</strong>
                    <span style="float: right; font-size: 0.9em;">{len(doc.paragraphs)} paragraphes</span>
                </div>
                <div style="padding: 20px; background: white; font-family: 'Times New Roman', serif; line-height: 1.6;">
                    {content}
                </div>
            </div>
            """

        except ImportError:
            logger.error("Module python-docx manquant")
            return (
                "<p style='color: #f44336; padding: 20px;'>"
                "‚ùå Module python-docx manquant (pip install python-docx)</p>"
            )

        except PermissionError:
            logger.error(f"Permission refus√©e pour Word: {file_path}")
            return "<p style='color: #f44336; padding: 20px;'>‚ùå Acc√®s refus√© au fichier Word</p>"

        except ValueError as e:
            # Fichier corrompu ou prot√©g√©
            logger.error(f"Fichier Word invalide: {e}")
            if "password" in str(e).lower() or "encrypted" in str(e).lower():
                return "<p style='color: #f44336; padding: 20px;'>üîí Fichier Word prot√©g√© par mot de passe</p>"
            return "<p style='color: #f44336; padding: 20px;'>‚ùå Fichier Word corrompu ou format invalide</p>"

        except MemoryError:
            logger.error(f"M√©moire insuffisante pour Word: {file_path}")
            return "<p style='color: #f44336; padding: 20px;'>‚ùå Fichier Word trop volumineux pour l'aper√ßu</p>"

        except Exception as e:
            logger.error(f"Erreur lecture Word: {e}")
            error_str = str(e)
            if "not a zip file" in error_str.lower() or "corrupt" in error_str.lower():
                return "<p style='color: #f44336; padding: 20px;'>‚ùå Fichier Word corrompu (format zip invalide)</p>"
            return (
                f"<p style='color: #f44336; padding: 20px;'>‚ùå Erreur lecture Word: {error_str}</p>"
            )

    def export_analysis_results(
        self, export_format: str
    ) -> Tuple[Optional[str], str]:  # noqa: C901
        """
        Exporter les resultats d'analyse dans le format choisi (Phase 6.1: Enhanced)

        Args:
            export_format: Format d'export (JSON, CSV, Excel)

        Returns:
            Tuple[Optional[str], str]: (file_path, status_message) or (None, error_message)
        """
        if not self.last_analysis_results:
            return None, "‚ö†Ô∏è Aucune analyse disponible √† exporter. Analysez d'abord un document."

        # Phase 6.1: V√©rifier l'espace disque disponible
        if not check_disk_space(required_bytes=10 * 1024 * 1024):  # 10 MB requis
            logger.error("‚ùå Espace disque insuffisant pour export")
            return None, ERROR_MESSAGES["disk_space"]

        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename_base = f"filagent_analysis_{timestamp}"

            if export_format == "JSON":
                return self._export_as_json(filename_base)
            elif export_format == "CSV":
                return self._export_as_csv(filename_base)
            elif export_format == "Excel":
                return self._export_as_excel(filename_base)
            else:
                logger.warning(f"Format non support√©: {export_format}")
                return (
                    None,
                    f"‚ùå Format {export_format} non support√©. Choisissez JSON, CSV ou Excel.",
                )

        except MemoryError:
            logger.error("‚ùå M√©moire insuffisante pour export")
            return None, ERROR_MESSAGES["memory_error"]

        except PermissionError:
            logger.error("‚ùå Permission refus√©e pour export")
            return None, ERROR_MESSAGES["permission_denied"]

        except OSError as e:
            # Erreurs li√©es au syst√®me de fichiers
            logger.error(f"‚ùå Erreur syst√®me export: {e}")
            if "No space left" in str(e):
                return None, ERROR_MESSAGES["disk_space"]
            return None, ERROR_MESSAGES["export_failed"] + f"\n\n**D√©tail**: {str(e)}"

        except Exception as e:
            logger.error(f"‚ùå Erreur inattendue export: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return None, ERROR_MESSAGES["export_failed"] + f"\n\n**D√©tail**: {str(e)}"

    def _export_as_json(self, filename_base: str) -> Tuple[str, str]:
        """Exporter en JSON"""
        import tempfile

        export_data: Dict[str, Union[str, MetadataDict, Dict[str, Union[str, bool]], None]] = {
            "timestamp": datetime.now().isoformat(),
            "filename": (
                Path(self.last_analyzed_file).name if self.last_analyzed_file else "unknown"
            ),
            "analysis_results": self.last_analysis_results,
            "metadata": {
                "version": "1.0.0",
                "tool": "FilAgent Document Analyzer",
                "compliant": True,
            },
        }

        # Signer les donn√©es
        signature = self.engine.security.sign_data(json.dumps(export_data, default=str))
        export_data["signature"] = signature

        # Sauvegarder dans un fichier temporaire
        temp_file = tempfile.NamedTemporaryFile(
            mode="w", suffix=".json", prefix=filename_base + "_", delete=False
        )

        json.dump(export_data, temp_file, indent=2, ensure_ascii=False)
        temp_file.close()

        logger.info(f"‚úÖ Export JSON cr√©√©: {temp_file.name}")
        return temp_file.name, "‚úÖ Export JSON cr√©√© avec succ√®s"

    def _export_as_csv(self, filename_base: str) -> Tuple[str, str]:
        """Exporter en CSV"""
        import tempfile
        import csv

        # Convertir les resultats en format tabulaire
        rows: List[List[str]] = []
        if isinstance(self.last_analysis_results, dict):
            for key, value in self.last_analysis_results.items():
                rows.append([key, str(value)])
        else:
            rows.append(["results", str(self.last_analysis_results)])

        # Cr√©er le fichier CSV
        temp_file = tempfile.NamedTemporaryFile(
            mode="w",
            suffix=".csv",
            prefix=filename_base + "_",
            delete=False,
            newline="",
            encoding="utf-8",
        )

        writer = csv.writer(temp_file)
        writer.writerow(["Champ", "Valeur"])  # Header
        writer.writerows(rows)
        temp_file.close()

        logger.info(f"‚úÖ Export CSV cr√©√©: {temp_file.name}")
        return temp_file.name, "‚úÖ Export CSV cr√©√© avec succ√®s"

    def _export_as_excel(self, filename_base: str) -> Tuple[str, str]:
        """Exporter en Excel"""
        import tempfile

        # Pr√©parer les donn√©es pour DataFrame
        if isinstance(self.last_analysis_results, dict):
            df = pd.DataFrame([self.last_analysis_results])
        else:
            df = pd.DataFrame([{"results": str(self.last_analysis_results)}])

        # Cr√©er le fichier Excel
        temp_file = tempfile.NamedTemporaryFile(
            suffix=".xlsx", prefix=filename_base + "_", delete=False
        )
        temp_file.close()  # Fermer pour que pandas puisse √©crire

        # √âcrire avec pandas
        with pd.ExcelWriter(temp_file.name, engine="openpyxl") as writer:
            df.to_excel(writer, sheet_name="Analysis Results", index=False)

            # Ajouter une feuille de m√©tadonn√©es
            metadata_df = pd.DataFrame(
                [
                    {
                        "Timestamp": datetime.now().isoformat(),
                        "Fichier": (
                            Path(self.last_analyzed_file).name
                            if self.last_analyzed_file
                            else "unknown"
                        ),
                        "Tool": "FilAgent Document Analyzer",
                        "Version": "1.0.0",
                    }
                ]
            )
            metadata_df.to_excel(writer, sheet_name="Metadata", index=False)

        logger.info(f"‚úÖ Export Excel cr√©√©: {temp_file.name}")
        return temp_file.name, "‚úÖ Export Excel cr√©√© avec succ√®s"

    def create_download_zip(self) -> Tuple[Optional[str], str]:  # noqa: C901
        """
        Creer un ZIP contenant le fichier analyse + resultats exportes (Phase 6.1: Enhanced)

        Returns:
            Tuple[Optional[str], str]: (zip_path, status_message) or (None, error_message)
        """
        if not self.last_analyzed_file or not self.last_analysis_results:
            return None, "‚ö†Ô∏è Aucune analyse disponible pour cr√©er le ZIP"

        # Phase 6.1: Verifier l'espace disque (100 MB pour etre sur)
        if not check_disk_space(required_bytes=100 * 1024 * 1024):
            logger.error("Espace disque insuffisant pour ZIP")
            return None, ERROR_MESSAGES["disk_space"]

        # Variables pour cleanup en cas d'erreur
        temp_files_to_cleanup: List[str] = []
        temp_zip_path: Optional[str] = None

        try:
            import tempfile
            import zipfile

            # Cr√©er un fichier ZIP temporaire
            temp_zip = tempfile.NamedTemporaryFile(suffix=".zip", prefix="filagent_", delete=False)
            temp_zip_path = temp_zip.name
            temp_zip.close()

            with zipfile.ZipFile(temp_zip_path, "w", zipfile.ZIP_DEFLATED) as zipf:
                # 1. Ajouter le fichier original analys√©
                if Path(self.last_analyzed_file).exists():
                    zipf.write(
                        self.last_analyzed_file,
                        arcname=f"original_{Path(self.last_analyzed_file).name}",
                    )
                else:
                    logger.warning(f"‚ö†Ô∏è Fichier original introuvable: {self.last_analyzed_file}")

                # 2. Ajouter les r√©sultats en JSON
                json_path, json_msg = self._export_as_json("results")
                if json_path:
                    temp_files_to_cleanup.append(json_path)
                    zipf.write(json_path, arcname="analysis_results.json")
                else:
                    logger.warning(f"‚ö†Ô∏è √âchec export JSON: {json_msg}")

                # 3. Ajouter les r√©sultats en CSV
                csv_path, csv_msg = self._export_as_csv("results")
                if csv_path:
                    temp_files_to_cleanup.append(csv_path)
                    zipf.write(csv_path, arcname="analysis_results.csv")
                else:
                    logger.warning(f"‚ö†Ô∏è √âchec export CSV: {csv_msg}")

                # 4. Ajouter les r√©sultats en Excel
                excel_path, excel_msg = self._export_as_excel("results")
                if excel_path:
                    temp_files_to_cleanup.append(excel_path)
                    zipf.write(excel_path, arcname="analysis_results.xlsx")
                else:
                    logger.warning(f"‚ö†Ô∏è √âchec export Excel: {excel_msg}")

                # 5. Ajouter un README
                readme_content = f"""FilAgent - Package d'Analyse de Document
=====================================

Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Fichier analys√©: {Path(self.last_analyzed_file).name}

Contenu du package:
-------------------
1. original_* - Le document original analys√©
2. analysis_results.json - R√©sultats au format JSON (sign√©)
3. analysis_results.csv - R√©sultats au format CSV
4. analysis_results.xlsx - R√©sultats au format Excel

Conformit√©:
-----------
‚úÖ Decision Record cr√©√©
‚úÖ Audit trail enregistr√©
‚úÖ Signature EdDSA appliqu√©e
‚úÖ Conforme Loi 25 / PIPEDA

FilAgent v1.0.0
https://github.com/your-org/filagent
"""
                zipf.writestr("README.txt", readme_content)

            # Phase 6.1: Cleanup des fichiers temporaires
            cleanup_temp_files(*temp_files_to_cleanup)

            # V√©rifier que le ZIP a √©t√© cr√©√© correctement
            zip_size = Path(temp_zip_path).stat().st_size
            if zip_size == 0:
                raise ValueError("Le fichier ZIP cr√©√© est vide")

            logger.info(f"‚úÖ ZIP cr√©√©: {temp_zip_path} ({zip_size // 1024} KB)")
            return temp_zip_path, f"‚úÖ Package ZIP cr√©√© avec succ√®s ({zip_size // 1024} KB)"

        except MemoryError:
            logger.error("‚ùå M√©moire insuffisante pour ZIP")
            cleanup_temp_files(*temp_files_to_cleanup, temp_zip_path)
            return None, ERROR_MESSAGES["memory_error"]

        except PermissionError:
            logger.error("‚ùå Permission refus√©e pour ZIP")
            cleanup_temp_files(*temp_files_to_cleanup, temp_zip_path)
            return None, ERROR_MESSAGES["permission_denied"]

        except OSError as e:
            logger.error(f"‚ùå Erreur syst√®me ZIP: {e}")
            cleanup_temp_files(*temp_files_to_cleanup, temp_zip_path)
            if "No space left" in str(e):
                return None, ERROR_MESSAGES["disk_space"]
            return None, ERROR_MESSAGES["export_failed"] + f"\n\n**D√©tail**: {str(e)}"

        except zipfile.BadZipFile as e:
            logger.error(f"‚ùå Erreur ZIP invalide: {e}")
            cleanup_temp_files(*temp_files_to_cleanup, temp_zip_path)
            return None, "‚ùå Erreur lors de la cr√©ation du fichier ZIP\n\nüí° R√©essayez l'op√©ration"

        except Exception as e:
            logger.error(f"‚ùå Erreur inattendue ZIP: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            cleanup_temp_files(*temp_files_to_cleanup, temp_zip_path)
            return None, ERROR_MESSAGES["export_failed"] + f"\n\n**D√©tail**: {str(e)}"

    def change_model_handler(self, backend: str, model_choice: str) -> str:
        """
        Gestionnaire pour changer de modele dynamiquement

        Args:
            backend: "perplexity" ou "openai"
            model_choice: Nom complet du modele choisi dans la liste

        Returns:
            Message de statut
        """
        # Mappings des modeles selon le backend
        perplexity_models: Dict[str, str] = {
            "Sonar (Rapide)": "sonar",
            "Sonar Pro (Equilibre) - Recommande": "sonar-pro",
            "Sonar Reasoning (Raisonnement)": "sonar-reasoning",
            "Sonar Reasoning Pro (Expert DeepSeek)": "sonar-reasoning-pro",
            "Sonar Deep Research (Recherche Approfondie)": "sonar-deep-research",
        }

        openai_models: Dict[str, str] = {
            "GPT-4o Mini (Rapide & Economique) - Recommande": "gpt-4o-mini",
            "GPT-4o (Flagship Multimodal)": "gpt-4o",
            "GPT-4 Turbo (Generation precedente)": "gpt-4-turbo",
            "GPT-3.5 Turbo (Tres economique)": "gpt-3.5-turbo",
        }

        # Extraire le nom du modele
        if backend == "perplexity":
            model_name = perplexity_models.get(model_choice, "sonar-pro")
        elif backend == "openai":
            model_name = openai_models.get(model_choice, "gpt-4o-mini")
        else:
            return f"Backend inconnu: {backend}"

        # Recharger le modele
        return self.engine.reload_model(backend, model_name)


def create_gradio_interface() -> gr.Blocks:  # noqa: C901
    """Cr√©er l'interface Gradio compl√®te"""

    interface = FilAgentInterface()

    with gr.Blocks(
        title="FilAgent - Assistant IA PME Qu√©bec",
        theme=gr.themes.Soft(
            primary_hue="blue", secondary_hue="gray", font=["Inter", "system-ui", "sans-serif"]
        ),
        css="""
        .gradio-container {
            font-family: 'Inter', system-ui, sans-serif !important;
        }
        .message-wrap {
            border-radius: 12px !important;
        }
        footer {visibility: hidden}
        """,
    ) as app:

        # √âtat de l'application
        _conversation_id = gr.State(value=str(uuid.uuid4()))

        # En-t√™te
        gr.Markdown("""
        # ü§ñ **FilAgent** - Assistant IA pour PME Qu√©b√©coises
        ### üîí Safety by Design | üèõÔ∏è 100% Conforme Loi 25 | üíª Donn√©es 100% Locales
        """)

        with gr.Tabs():
            # ========== ONGLET CHAT ==========
            with gr.Tab("üí¨ Assistant", id=1):
                with gr.Row():
                    with gr.Column(scale=3):
                        chatbot = gr.Chatbot(
                            label="Conversation",
                            height=500,
                            bubble_full_width=False,
                            show_copy_button=True,
                        )

                        with gr.Row():
                            msg = gr.Textbox(
                                label="Message",
                                placeholder="Tapez votre message... Ex: Calcule TPS/TVQ sur 500$",
                                lines=2,
                                scale=4,
                            )

                            with gr.Column(scale=1):
                                send = gr.Button("üì§ Envoyer", variant="primary")
                                clear = gr.Button("üóëÔ∏è Effacer")

                        # Exemples
                        gr.Examples(
                            examples=[
                                "Calcule les taxes sur 1500$",
                                "V√©rifie ma conformit√© Loi 25",
                                "Analyse cette facture",
                                "G√©n√®re un rapport mensuel",
                                "Comment fonctionne la signature EdDSA?",
                                "Montre-moi les m√©triques syst√®me",
                            ],
                            inputs=msg,
                            label="üí° Exemples de requ√™tes",
                        )

                    with gr.Column(scale=1):
                        # === NOUVEAUX PARAM√àTRES MOD√àLE ===
                        gr.Markdown("### ‚öôÔ∏è Param√®tres Mod√®le")

                        with gr.Group():
                            backend_selector = gr.Radio(
                                choices=["perplexity", "openai"],
                                value="perplexity",
                                label="Backend API",
                                info="Choisir le fournisseur d'IA",
                            )

                            perplexity_models = gr.Radio(
                                choices=[
                                    "Sonar (Rapide)",
                                    "Sonar Pro (√âquilibr√©) - Recommand√©",
                                    "Sonar Reasoning (Raisonnement)",
                                    "Sonar Reasoning Pro (Expert DeepSeek)",
                                    "Sonar Deep Research (Recherche Approfondie)",
                                ],
                                value="Sonar Pro (√âquilibr√©) - Recommand√©",
                                label="Mod√®le Perplexity",
                                visible=True,
                            )

                            openai_models = gr.Radio(
                                choices=[
                                    "GPT-4o Mini (Rapide & √âconomique) - Recommand√©",
                                    "GPT-4o (Flagship Multimodal)",
                                    "GPT-4 Turbo (G√©n√©ration pr√©c√©dente)",
                                    "GPT-3.5 Turbo (Tr√®s √©conomique)",
                                ],
                                value="GPT-4o Mini (Rapide & √âconomique) - Recommand√©",
                                label="Mod√®le OpenAI",
                                visible=False,
                            )

                            change_model_btn = gr.Button(
                                "üîÑ Changer Mod√®le", variant="primary", size="sm"
                            )
                            model_status = gr.Textbox(
                                label="Statut",
                                value="‚úÖ Mod√®le charg√©: perplexity/sonar-pro",
                                interactive=False,
                                lines=2,
                            )

                        gr.Markdown("### ‚ö° Actions Rapides")

                        with gr.Group():
                            calc_btn = gr.Button("üí∞ Calculateur Taxes", size="sm")
                            doc_btn = gr.Button("üìÑ Analyser Document", size="sm")
                            compliance_btn = gr.Button("üîí Audit Conformit√©", size="sm")
                            report_btn = gr.Button("üìä G√©n√©rer Rapport", size="sm")

                        gr.Markdown("### üìà Statut")
                        metrics_display = gr.Markdown(interface.get_metrics_display())
                        refresh_btn = gr.Button("üîÑ Actualiser", size="sm")

                        gr.Markdown("### üíæ Export")
                        export_btn = gr.Button("üì• Exporter JSON", size="sm")
                        export_output = gr.Textbox(label="Export", lines=5, visible=False)

            # ========== ONGLET OUTILS ==========
            with gr.Tab("üõ†Ô∏è Outils PME", id=2):
                gr.Markdown("## Outils Sp√©cialis√©s PME")

                # ========== ANALYSEUR DE DOCUMENTS (NOUVEAU) ==========
                with gr.Accordion("üìÑ Analyseur de Documents - REAL TOOL", open=True):
                    gr.Markdown("""
                    ### üîç Analyse Intelligente de Documents
                    T√©l√©versez vos factures, √©tats financiers ou rapports
                    pour une analyse automatique avec calculs TPS/TVQ.

                    **Formats support√©s**: PDF, Excel (.xlsx, .xls), Word (.docx, .doc)
                    """)

                    with gr.Row():
                        with gr.Column(scale=2):
                            # Upload de fichier
                            doc_file_upload = gr.File(
                                label="üìÇ T√©l√©verser un document",
                                file_types=[".pdf", ".xlsx", ".xls", ".docx", ".doc"],
                                type="filepath",
                                file_count="single",
                            )

                            # Type d'analyse
                            doc_analysis_type = gr.Radio(
                                choices=["invoice", "extract", "financial", "contract", "report"],
                                value="invoice",
                                label="Type d'analyse",
                                info="invoice=TPS/TVQ | extract=Donnees brutes | financial=Bilans/Budgets | contract=Clauses juridiques | report=Rapport general",
                            )

                            # Bouton d'analyse
                            with gr.Row():
                                doc_analyze_btn = gr.Button(
                                    "üîç Analyser Document", variant="primary", size="lg"
                                )
                                doc_clear_btn = gr.Button(
                                    "üóëÔ∏è Effacer", variant="secondary", size="lg"
                                )

                        with gr.Column(scale=3):
                            # R√©sultats de l'analyse
                            doc_analysis_output = gr.Markdown(
                                value="""üìÑ **En attente d'un document...**

T√©l√©versez un fichier pour commencer l'analyse.

**Capacit√©s**:
‚úÖ Extraction automatique de montants
‚úÖ Calcul TPS (5%) et TVQ (9.975%)
‚úÖ D√©tection de num√©ros fiscaux
‚úÖ Redaction PII (conformit√© Loi 25)

üîí *Traitement 100% local et s√©curis√©*""",
                                label="R√©sultats d'Analyse",
                            )

                    # Zone d'aper√ßu (ACTIV√âE - Phase 4)
                    with gr.Accordion(
                        "üëÅÔ∏è Aper√ßu du Document", open=False
                    ) as _doc_preview_accordion:
                        doc_preview_html = gr.HTML(
                            label="Contenu",
                            value=(
                                "<p style='color: #999; padding: 20px; text-align: center;'>"
                                "üìÑ T√©l√©versez un document pour voir l'aper√ßu</p>"
                            ),
                        )

                        # Bouton de t√©l√©chargement (Phase 4.3)
                        with gr.Row():
                            doc_download_btn = gr.Button(
                                "‚¨áÔ∏è T√©l√©charger le Document",
                                variant="secondary",
                                size="sm",
                                visible=False,
                            )
                            doc_download_file = gr.File(
                                label="Fichier √† t√©l√©charger", visible=False, interactive=False
                            )

                    # ========== EXPORT R√âSULTATS (Phase 5) ==========
                    gr.Markdown("---")
                    with gr.Accordion(
                        "üì§ Exporter les R√©sultats", open=False
                    ) as _doc_export_accordion:
                        gr.Markdown("""
                        ### üíæ Formats d'Export Disponibles

                        Exportez les r√©sultats d'analyse dans le format de votre choix.
                        """)

                        with gr.Row():
                            with gr.Column(scale=2):
                                # S√©lecteur de format
                                export_format_selector = gr.Radio(
                                    choices=["JSON", "CSV", "Excel"],
                                    value="JSON",
                                    label="Format d'export",
                                    info="JSON (complet + signature) | CSV (tableau) | Excel (multi-feuilles)",
                                )

                                # Boutons d'export
                                with gr.Row():
                                    export_single_btn = gr.Button(
                                        "üìÑ Exporter R√©sultats", variant="primary", size="lg"
                                    )
                                    export_all_btn = gr.Button(
                                        "üì¶ Tout T√©l√©charger (ZIP)", variant="secondary", size="lg"
                                    )

                            with gr.Column(scale=1):
                                # Statut d'export
                                export_status = gr.Markdown(
                                    value="**Statut**: En attente d'export", label="Statut"
                                )

                        # Fichier d'export (cach√©, utilis√© pour le download)
                        export_file_output = gr.File(
                            label="Fichier export√©", visible=False, interactive=False
                        )

                # ========== CALCULATEUR MATHEMATIQUE ==========
                gr.Markdown("---")
                with gr.Accordion("üî¢ Calculateur Math√©matique", open=False):
                    gr.Markdown("""
                    ### üßÆ √âvaluation d'Expressions Math√©matiques

                    √âvaluez des expressions math√©matiques de mani√®re s√©curis√©e.
                    Supporte: op√©rations de base, fonctions trigonom√©triques, logarithmes, etc.

                    **Exemples**: `2 + 3 * 4`, `sqrt(16)`, `sin(3.14159/2)`, `log(100)`
                    """)

                    with gr.Row():
                        with gr.Column(scale=2):
                            calc_expression_input = gr.Textbox(
                                label="Expression math√©matique",
                                placeholder="Ex: 2 + 3 * 4, sqrt(16), sin(3.14159)",
                                lines=2,
                            )
                            with gr.Row():
                                calc_execute_btn = gr.Button(
                                    "üßÆ Calculer", variant="primary", size="lg"
                                )
                                calc_clear_btn = gr.Button(
                                    "üóëÔ∏è Effacer", variant="secondary", size="lg"
                                )

                            # Exemples
                            gr.Examples(
                                examples=[
                                    "2 + 3 * 4",
                                    "sqrt(16) + 2",
                                    "sin(3.14159 / 2)",
                                    "log(100)",
                                    "(10 + 5) * 3 / 2",
                                    "2 ** 10",
                                ],
                                inputs=calc_expression_input,
                                label="Exemples d'expressions",
                            )

                        with gr.Column(scale=1):
                            calc_result_output = gr.Markdown(
                                value="**R√©sultat**: En attente d'une expression...",
                                label="R√©sultat",
                            )

                # ========== SANDBOX PYTHON ==========
                with gr.Accordion("üêç Sandbox Python", open=False):
                    gr.Markdown("""
                    ### üîí Ex√©cution Python S√©curis√©e

                    Ex√©cutez du code Python dans un environnement sandbox isol√©.
                    Limites: CPU 30s, M√©moire 512 MB, pas d'acc√®s r√©seau/fichiers.

                    **S√©curit√©**: Validation AST, blocage imports dangereux, isolation processus.
                    """)

                    with gr.Row():
                        with gr.Column(scale=2):
                            sandbox_code_input = gr.Code(
                                label="Code Python",
                                language="python",
                                value="# Exemple: calcul simple\nresult = sum(range(1, 11))\nprint(f'Somme de 1 √† 10 = {result}')",
                                lines=10,
                            )
                            with gr.Row():
                                sandbox_execute_btn = gr.Button(
                                    "‚ñ∂Ô∏è Ex√©cuter", variant="primary", size="lg"
                                )
                                sandbox_clear_btn = gr.Button(
                                    "üóëÔ∏è Effacer", variant="secondary", size="lg"
                                )

                        with gr.Column(scale=1):
                            sandbox_output = gr.Markdown(
                                value="**Sortie**: En attente d'ex√©cution...",
                                label="Sortie",
                            )
                            sandbox_status = gr.Markdown(
                                value="**Statut**: Pr√™t",
                                label="Statut",
                            )

                # ========== LECTEUR DE FICHIERS ==========
                with gr.Accordion("üìÇ Lecteur de Fichiers", open=False):
                    gr.Markdown("""
                    ### üìñ Lecture S√©curis√©e de Fichiers

                    Lisez le contenu de fichiers texte dans les r√©pertoires autoris√©s.
                    Taille max: 10 MB. Protection contre path traversal et symlinks.

                    **R√©pertoires autoris√©s**: `working_set/`, `temp/`, `memory/working_set/`
                    """)

                    with gr.Row():
                        with gr.Column(scale=2):
                            file_path_input = gr.Textbox(
                                label="Chemin du fichier",
                                placeholder="Ex: working_set/data.txt",
                                lines=1,
                            )
                            with gr.Row():
                                file_read_btn = gr.Button("üìñ Lire", variant="primary", size="lg")
                                file_clear_btn = gr.Button(
                                    "üóëÔ∏è Effacer", variant="secondary", size="lg"
                                )

                        with gr.Column(scale=2):
                            file_content_output = gr.Textbox(
                                label="Contenu du fichier",
                                value="",
                                lines=15,
                                interactive=False,
                                show_copy_button=True,
                            )
                            file_status_output = gr.Markdown(
                                value="**Statut**: En attente d'un chemin...",
                                label="Statut",
                            )

            # ========== ONGLET CONFORMIT√â ==========
            with gr.Tab("üîí Conformit√©", id=3):
                gr.Markdown("""
                ## Tableau de Bord Conformit√©

                ### ‚úÖ Certifications Actives
                - **Loi 25 (Qu√©bec)**: Protection renseignements personnels
                - **RGPD**: R√®glement g√©n√©ral protection donn√©es
                - **AI Act**: R√©glementation IA europ√©enne
                - **ISO 27001**: S√©curit√© information
                - **NIST AI RMF**: Framework gestion risques IA

                ### üîê Mesures de S√©curit√©
                - Signatures EdDSA sur toutes les d√©cisions
                - Logs WORM immuables (Write Once Read Many)
                - Cha√Æne Merkle pour int√©grit√©
                - Chiffrement AES-256 au repos
                - Isolation sandbox pour ex√©cution

                ### üìä M√©triques de Conformit√©
                - Taux redaction PII: 100%
                - Decision Records sign√©s: 100%
                - Audit trail complet: 100%
                - R√©tention conforme: 90 jours
                """)

        # ========== CONNEXIONS √âV√âNEMENTS ==========

        # Chat principal
        msg.submit(
            lambda m, h: asyncio.run(interface.chat_handler(m, h)),
            inputs=[msg, chatbot],
            outputs=[msg, chatbot],
        )

        send.click(
            lambda m, h: asyncio.run(interface.chat_handler(m, h)),
            inputs=[msg, chatbot],
            outputs=[msg, chatbot],
        )

        # Boutons actions
        clear.click(interface.clear_conversation, outputs=[msg, chatbot])

        calc_btn.click(
            lambda h: asyncio.run(interface.chat_handler("Active le calculateur de taxes", h)),
            inputs=[chatbot],
            outputs=[msg, chatbot],
        )

        doc_btn.click(
            lambda h: asyncio.run(interface.chat_handler("Active l'analyseur de documents", h)),
            inputs=[chatbot],
            outputs=[msg, chatbot],
        )

        compliance_btn.click(
            lambda h: asyncio.run(interface.chat_handler("Lance un audit de conformit√©", h)),
            inputs=[chatbot],
            outputs=[msg, chatbot],
        )

        # === EVENT HANDLERS PARAM√àTRES MOD√àLE ===
        # Changer visibilit√© des mod√®les selon le backend s√©lectionn√©
        def toggle_model_visibility(backend: str) -> Tuple[Dict[str, bool], Dict[str, bool]]:
            if backend == "perplexity":
                return gr.update(visible=True), gr.update(visible=False)
            else:  # openai
                return gr.update(visible=False), gr.update(visible=True)

        backend_selector.change(
            toggle_model_visibility,
            inputs=[backend_selector],
            outputs=[perplexity_models, openai_models],
        )

        # Changer de modele
        def change_model(backend: str, perplexity_choice: str, openai_choice: str) -> str:
            model_choice = perplexity_choice if backend == "perplexity" else openai_choice
            return interface.change_model_handler(backend, model_choice)

        change_model_btn.click(
            change_model,
            inputs=[backend_selector, perplexity_models, openai_models],
            outputs=[model_status],
        )

        report_btn.click(
            lambda h: asyncio.run(interface.chat_handler("G√©n√®re un rapport", h)),
            inputs=[chatbot],
            outputs=[msg, chatbot],
        )

        # M√©triques
        refresh_btn.click(lambda: interface.get_metrics_display(), outputs=[metrics_display])

        # Export
        export_btn.click(
            lambda h: (gr.update(visible=True), interface.export_conversation(h)),
            inputs=[chatbot],
            outputs=[export_output, export_output],
        )

        # ========== DOCUMENT ANALYZER EVENT HANDLERS ==========

        def handle_document_analysis(
            file_path: Optional[str], analysis_type: str
        ) -> Tuple[str, str, Dict[str, bool], Optional[str]]:
            """
            Handler pour l'analyse de documents avec vrai outil (Phase 6.1: Enhanced)

            Args:
                file_path: Chemin du fichier televerse (fourni par Gradio)
                analysis_type: Type d'analyse ('invoice' ou 'extract')

            Returns:
                Tuple: (results, preview_html, download_btn_visible, download_file_value)
            """
            if not file_path:
                return (
                    "‚ö†Ô∏è **Erreur**: Veuillez t√©l√©verser un fichier d'abord",
                    "<p style='color: #999;'>Aucun aper√ßu disponible</p>",
                    gr.update(visible=False),  # download_btn
                    None,  # download_file
                )

            # Phase 6.1: Validation PR√âCOCE du fichier
            is_valid, validation_error = validate_file(file_path)
            if not is_valid:
                logger.warning(f"‚ö†Ô∏è Validation √©chou√©e: {file_path}")
                return (
                    validation_error,
                    "<p style='color: #f44336; padding: 20px;'>‚ùå Fichier invalide</p>",
                    gr.update(visible=False),
                    None,
                )

            try:
                # R√©cup√©rer l'outil depuis l'engine
                doc_tool = interface.engine.tools.get("document_analyzer")

                if not doc_tool:
                    logger.error("‚ùå Document analyzer tool not found in engine")
                    return (
                        "‚ùå **Erreur syst√®me**: Outil non disponible\n\nüí° **Solution**: Red√©marrez l'application",
                        "<p style='color: #f44336;'>Erreur syst√®me</p>",
                        gr.update(visible=False),
                        None,
                    )

                # Analyser le document avec le vrai outil
                logger.info(f"üîç Analyse document: {file_path} (type: {analysis_type})")

                # Obtenir le r√©sultat format√© (string markdown)
                result_text = asyncio.run(
                    doc_tool.execute(file_path=file_path, analysis_type=analysis_type)
                )

                # Obtenir aussi les donn√©es brutes pour export
                # On appelle directement le real_tool pour avoir le ToolResult complet
                tool_result = doc_tool.real_tool.execute(
                    {"file_path": file_path, "analysis_type": analysis_type}
                )

                # Stocker les r√©sultats pour export (Phase 5)
                if tool_result.status == ToolStatus.SUCCESS and tool_result.metadata:
                    interface.last_analysis_results = tool_result.metadata
                    interface.last_analyzed_file = file_path
                    logger.info(
                        f"üíæ R√©sultats stock√©s pour export: {len(tool_result.metadata)} champs"
                    )
                else:
                    interface.last_analysis_results = {"raw_result": str(result_text)}
                    interface.last_analyzed_file = file_path

                # G√©n√©rer l'aper√ßu du fichier
                preview_html, preview_success = interface.render_file_preview(file_path)

                # Log Decision Record pour conformit√©
                filename = Path(file_path).name
                interface.engine.database.log_audit_event(
                    event_type="DOCUMENT_ANALYZED",
                    actor="user_gradio",
                    resource=filename,
                    action="ANALYZE",
                    outcome="SUCCESS",
                    metadata={
                        "analysis_type": analysis_type,
                        "file_size": (
                            Path(file_path).stat().st_size if Path(file_path).exists() else 0
                        ),
                    },
                )

                logger.info(f"‚úÖ Analyse compl√©t√©e: {filename}")

                # Retourner r√©sultats + aper√ßu + bouton download activ√©
                return (
                    result_text,
                    preview_html,
                    gr.update(visible=True),  # Activer bouton download
                    file_path,  # Fichier pour download
                )

            except FileNotFoundError:
                logger.error(f"‚ùå Fichier non trouv√©: {file_path}")
                return (
                    "‚ùå **Erreur**: Fichier non trouv√© apr√®s t√©l√©versement",
                    "<p style='color: #f44336;'>Fichier introuvable</p>",
                    gr.update(visible=False),
                    None,
                )

            except Exception as e:
                logger.error(f"‚ùå Erreur analyse document: {e}")
                logger.error(f"Traceback: {traceback.format_exc()}")
                error_msg = f"""‚ùå **Erreur d'Analyse**

**Message**: {str(e)}

**Actions sugg√©r√©es**:
1. V√©rifiez que le fichier n'est pas corrompu
2. Assurez-vous que le format est support√© (PDF, Excel, Word)
3. Essayez avec un fichier plus petit

üîí *L'erreur a √©t√© enregistr√©e dans les logs d'audit*"""
                return (
                    error_msg,
                    f"<p style='color: #f44336;'>Erreur: {str(e)}</p>",
                    gr.update(visible=False),
                    None,
                )

        def clear_document_analysis() -> Tuple[None, str, str, Dict[str, bool], None]:
            """Effacer les resultats d'analyse"""
            return (
                None,  # Clear file upload
                """En attente d'un document...

Televersez un fichier pour commencer l'analyse.

Capacites:
- Extraction automatique de montants
- Calcul TPS (5%) et TVQ (9.975%)
- Detection de numeros fiscaux
- Redaction PII (conformite Loi 25)

Traitement 100% local et securise""",
                (
                    "<p style='color: #999; padding: 20px; text-align: center;'>"
                    "Televersez un document pour voir l'apercu</p>"
                ),  # Reset preview
                gr.update(visible=False),  # Hide download button
                None,  # Clear download file
            )

        def show_file_preview(file_path: Optional[str]) -> str:
            """Afficher l'apercu quand un fichier est televerse"""
            if not file_path:
                return "<p style='color: #999; padding: 20px; text-align: center;'>Aucun fichier selectionne</p>"

            preview_html, _success = interface.render_file_preview(file_path)
            return preview_html

        # Connexion des √©v√©nements Document Analyzer
        doc_analyze_btn.click(
            handle_document_analysis,
            inputs=[doc_file_upload, doc_analysis_type],
            outputs=[doc_analysis_output, doc_preview_html, doc_download_btn, doc_download_file],
        )

        doc_clear_btn.click(
            clear_document_analysis,
            outputs=[
                doc_file_upload,
                doc_analysis_output,
                doc_preview_html,
                doc_download_btn,
                doc_download_file,
            ],
        )

        # Afficher l'aper√ßu automatiquement quand un fichier est upload√©
        doc_file_upload.change(
            show_file_preview, inputs=[doc_file_upload], outputs=[doc_preview_html]
        )

        # Handler pour le t√©l√©chargement
        doc_download_btn.click(
            lambda file: file, inputs=[doc_download_file], outputs=[doc_download_file]
        )

        # ========== EXPORT EVENT HANDLERS (Phase 5) ==========

        def handle_export_results(
            export_format: str,
        ) -> Tuple[Dict[str, Union[str, bool]], str]:
            """Handler pour exporter les resultats dans le format choisi"""
            file_path, status_msg = interface.export_analysis_results(export_format)

            if file_path:
                # Succes - retourner le fichier et le statut
                status_text = (
                    f"**{status_msg}**\n\n"
                    f"Format: {export_format}\n"
                    f"Fichier: `{Path(file_path).name}`"
                )
                return (
                    gr.update(value=file_path, visible=True),  # export_file_output
                    status_text,  # export_status
                )
            else:
                # Erreur - afficher le message d'erreur
                return (
                    gr.update(visible=False),  # export_file_output
                    f"**Erreur**\n\n{status_msg}",  # export_status
                )

        def handle_export_zip() -> Tuple[Dict[str, Union[str, bool]], str]:
            """Handler pour creer et telecharger le ZIP complet"""
            zip_path, status_msg = interface.create_download_zip()

            if zip_path:
                # Succes
                zip_status = (
                    f"**{status_msg}**\n\n"
                    "**Contenu du ZIP**:\n"
                    "- Document original\n"
                    "- Resultats JSON (signe)\n"
                    "- Resultats CSV\n"
                    "- Resultats Excel\n"
                    "- README.txt"
                )
                return (
                    gr.update(value=zip_path, visible=True),  # export_file_output
                    zip_status,  # export_status
                )
            else:
                # Erreur
                return (
                    gr.update(visible=False),  # export_file_output
                    f"**Erreur**\n\n{status_msg}",  # export_status
                )

        # Connexion des √©v√©nements Export
        export_single_btn.click(
            handle_export_results,
            inputs=[export_format_selector],
            outputs=[export_file_output, export_status],
        )

        export_all_btn.click(handle_export_zip, outputs=[export_file_output, export_status])

        # ========== CALCULATEUR MATHEMATIQUE EVENT HANDLERS ==========

        # Initialiser l'outil calculateur
        calculator_tool = CalculatorTool()

        def handle_calculator(expression: str) -> str:
            """Handler pour le calculateur mathematique"""
            if not expression or not expression.strip():
                return "**Resultat**: Veuillez entrer une expression mathematique"

            try:
                result = calculator_tool.execute({"expression": expression.strip()})

                if result.status == ToolStatus.SUCCESS:
                    metadata: MetadataDict = result.metadata or {}
                    return f"""**Resultat**: `{result.output}`

---

| Detail | Valeur |
|--------|--------|
| Expression | `{metadata.get('expression', expression)}` |
| Type | {metadata.get('result_type', 'number')} |

*Calcule de maniere securisee*
"""
                else:
                    return f"""**Erreur**: {result.error}

*Verifiez la syntaxe de l'expression*
"""
            except Exception as e:
                logger.error(f"Erreur calculateur: {e}")
                return f"**Erreur**: {str(e)}"

        def clear_calculator() -> Tuple[str, str]:
            """Effacer le calculateur"""
            return "", "**Resultat**: En attente d'une expression..."

        calc_execute_btn.click(
            handle_calculator,
            inputs=[calc_expression_input],
            outputs=[calc_result_output],
        )

        calc_clear_btn.click(
            clear_calculator,
            outputs=[calc_expression_input, calc_result_output],
        )

        # Ex√©cuter aussi sur Enter
        calc_expression_input.submit(
            handle_calculator,
            inputs=[calc_expression_input],
            outputs=[calc_result_output],
        )

        # ========== SANDBOX PYTHON EVENT HANDLERS ==========

        # Initialiser l'outil sandbox
        sandbox_tool = PythonSandboxTool()

        def handle_sandbox(code: str) -> Tuple[str, str]:
            """Handler pour le sandbox Python"""
            if not code or not code.strip():
                return (
                    "**Sortie**: Veuillez entrer du code Python",
                    "**Statut**: En attente de code",
                )

            try:
                logger.info(f"Execution sandbox: {len(code)} caracteres")
                result = sandbox_tool.execute({"code": code})

                if result.status == ToolStatus.SUCCESS:
                    metadata: MetadataDict = result.metadata or {}
                    elapsed_raw = metadata.get("elapsed_time", 0)
                    elapsed = float(elapsed_raw) if elapsed_raw is not None else 0.0
                    output_text = result.output or "[Aucune sortie]"

                    return (
                        f"""**Sortie**:
```
{output_text}
```
""",
                        f"""**Statut**: Execution reussie

| Metrique | Valeur |
|----------|--------|
| Temps | {elapsed:.3f}s |
| Code retour | {metadata.get('returncode', 0)} |
""",
                    )
                elif result.status == ToolStatus.TIMEOUT:
                    return (
                        "**Sortie**: *Timeout - ex√©cution trop longue*",
                        "**Statut**: Timeout (>30s)",
                    )
                elif result.status == ToolStatus.BLOCKED:
                    return (
                        f"**Sortie**: *Code bloqu√©*\n\n{result.error}",
                        "**Statut**: Bloqu√© (code dangereux d√©tect√©)",
                    )
                else:
                    return (
                        f"**Sortie**: *Erreur*\n\n{result.error}",
                        "**Statut**: Erreur d'ex√©cution",
                    )
            except Exception as e:
                logger.error(f"Erreur sandbox: {e}")
                return (
                    f"**Sortie**: *Exception*\n\n{str(e)}",
                    "**Statut**: Erreur syst√®me",
                )

        def clear_sandbox() -> Tuple[str, str, str]:
            """Effacer le sandbox"""
            return (
                "# Exemple: calcul simple\nresult = sum(range(1, 11))\nprint(f'Somme de 1 √† 10 = {result}')",
                "**Sortie**: En attente d'ex√©cution...",
                "**Statut**: Pr√™t",
            )

        sandbox_execute_btn.click(
            handle_sandbox,
            inputs=[sandbox_code_input],
            outputs=[sandbox_output, sandbox_status],
        )

        sandbox_clear_btn.click(
            clear_sandbox,
            outputs=[sandbox_code_input, sandbox_output, sandbox_status],
        )

        # ========== LECTEUR DE FICHIERS EVENT HANDLERS ==========

        # Initialiser l'outil lecteur
        file_reader_tool = FileReaderTool()

        def handle_file_read(file_path: str) -> Tuple[str, str]:
            """Handler pour le lecteur de fichiers"""
            if not file_path or not file_path.strip():
                return (
                    "",
                    "**Statut**: Veuillez entrer un chemin de fichier",
                )

            try:
                logger.info(f"Lecture fichier: {file_path}")
                result = file_reader_tool.execute({"file_path": file_path.strip()})

                if result.status == ToolStatus.SUCCESS:
                    metadata: MetadataDict = result.metadata or {}
                    file_size_raw = metadata.get("file_size", 0)
                    file_size = int(file_size_raw) if file_size_raw is not None else 0
                    content = result.output or ""

                    # Tronquer si trop long pour l'affichage
                    if len(content) > 50000:
                        content = content[:50000] + "\n\n... [Tronque - fichier trop long]"

                    return (
                        content,
                        f"""**Statut**: Lecture reussie

| Info | Valeur |
|------|--------|
| Taille | {file_size:,} bytes |
| Lignes | {len(content.splitlines())} |
""",
                    )
                elif result.status == ToolStatus.BLOCKED:
                    return (
                        "",
                        f"**Statut**: Bloque\n\n{result.error}\n\n*Seuls les repertoires autorises sont accessibles*",
                    )
                else:
                    return (
                        "",
                        f"**Statut**: Erreur\n\n{result.error}",
                    )
            except Exception as e:
                logger.error(f"Erreur lecture fichier: {e}")
                return ("", f"**Statut**: Exception\n\n{str(e)}")

        def clear_file_reader() -> Tuple[str, str, str]:
            """Effacer le lecteur"""
            return (
                "",
                "",
                "**Statut**: En attente d'un chemin...",
            )

        file_read_btn.click(
            handle_file_read,
            inputs=[file_path_input],
            outputs=[file_content_output, file_status_output],
        )

        file_clear_btn.click(
            clear_file_reader,
            outputs=[file_path_input, file_content_output, file_status_output],
        )

        # Ex√©cuter aussi sur Enter
        file_path_input.submit(
            handle_file_read,
            inputs=[file_path_input],
            outputs=[file_content_output, file_status_output],
        )

    return app


# ============================================================================
# POINT D'ENTR√âE PRINCIPAL
# ============================================================================

if __name__ == "__main__":
    import sys

    # Configuration logging
    # Determine log directory from environment or relative to script
    base_dir = Path(os.environ.get("FILAGENT_BASE_DIR", Path(__file__).parent.resolve()))
    logs_dir = base_dir / "logs"
    logs_dir.mkdir(parents=True, exist_ok=True)

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(logs_dir / "gradio.log"),
            logging.StreamHandler(sys.stdout),
        ],
    )

    logger.info("=" * 60)
    logger.info("üöÄ D√©marrage de FilAgent Interface")
    logger.info("=" * 60)

    try:
        # Cr√©er et lancer l'interface
        app = create_gradio_interface()

        logger.info("‚úÖ Interface cr√©√©e avec succ√®s")
        logger.info("üåê Lancement sur http://localhost:7860")

        # Lancer le serveur
        app.launch(
            server_name="0.0.0.0", server_port=7860, share=False, show_error=True, quiet=False
        )

    except Exception as e:
        logger.error(f"‚ùå Erreur fatale: {e}")
        logger.error(traceback.format_exc())
        sys.exit(1)
