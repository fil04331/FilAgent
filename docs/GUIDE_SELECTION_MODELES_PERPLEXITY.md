# Guide de S√©lection des Mod√®les Perplexity - FilAgent

**Date**: 2025-11-17
**Version**: 1.0.0
**Auteur**: FilAgent Team

---

## üìã Table des Mati√®res

1. [Pr√©sentation](#pr√©sentation)
2. [Mod√®les Disponibles](#mod√®les-disponibles)
3. [Interface de S√©lection](#interface-de-s√©lection)
4. [Scripts de Benchmark](#scripts-de-benchmark)
5. [Recommandations par Difficult√©](#recommandations-par-difficult√©)
6. [Guide d'Utilisation](#guide-dutilisation)

---

## üéØ Pr√©sentation

Ce document d√©crit le syst√®me de s√©lection dynamique de mod√®les Perplexity int√©gr√© √† FilAgent. Le syst√®me permet de:

- **Choisir le mod√®le optimal** selon la difficult√© de la requ√™te
- **Comparer les performances** de diff√©rents mod√®les
- **Optimiser les co√ªts** en utilisant le bon mod√®le au bon moment
- **Maintenir la qualit√©** tout en contr√¥lant la latence

### Nouveaux Fichiers Cr√©√©s

1. **Interface Gradio avec s√©lecteur**: `gradio_app_model_selector.py`
2. **Script de benchmark complet**: `scripts/benchmark_perplexity_models.py`
3. **Script de d√©monstration rapide**: `scripts/demo_model_comparison.py`
4. **Ce guide**: `docs/GUIDE_SELECTION_MODELES_PERPLEXITY.md`

---

## üìä Mod√®les Disponibles

FilAgent supporte 5 mod√®les Perplexity avec des caract√©ristiques distinctes:

### 1. Sonar Small - Rapide üöÄ

**Nom complet**: `llama-3.1-sonar-small-128k-online`

- **Latence**: Tr√®s faible (<300ms)
- **Qualit√©**: Bonne pour questions simples
- **Co√ªt**: $ (√©conomique)
- **Fonctionnalit√©s**: Recherche web, Rapide
- **Cas d'usage**: FAQ, calculs simples, recherche factuelle

**Quand l'utiliser**:
- Questions factuelles directes
- Calculs simples (TPS/TVQ)
- Recherches d'information basiques
- Lorsque la vitesse est prioritaire

### 2. Sonar Large - √âquilibr√© ‚öñÔ∏è

**Nom complet**: `llama-3.1-sonar-large-128k-online`

- **Latence**: Faible (<500ms)
- **Qualit√©**: Tr√®s bonne
- **Co√ªt**: $$ (mod√©r√©)
- **Fonctionnalit√©s**: Recherche web, √âquilibr√©
- **Cas d'usage**: Analyse de conformit√©, explications techniques

**Quand l'utiliser**:
- Analyse de conformit√© (Loi 25, RGPD)
- Explications techniques d√©taill√©es
- Raisonnement mod√©r√©
- **Recommand√© comme d√©faut** pour usage g√©n√©ral

### 3. Sonar Huge - Maximum Qualit√© üéØ

**Nom complet**: `llama-3.1-sonar-huge-128k-online`

- **Latence**: Moyenne (<1s)
- **Qualit√©**: Excellence
- **Co√ªt**: $$$ (premium)
- **Fonctionnalit√©s**: Recherche web, Pr√©cis, Complexe
- **Cas d'usage**: Analyse juridique, d√©cisions automatis√©es

**Quand l'utiliser**:
- Raisonnement complexe multi-√©tapes
- Analyse juridique approfondie
- D√©cisions automatis√©es critiques
- Lorsque la qualit√© est absolument prioritaire

### 4. Llama 8B Instruct - √âconomique üí∞

**Nom complet**: `llama-3.1-8b-instruct`

- **Latence**: Tr√®s faible (<200ms)
- **Qualit√©**: Bonne
- **Co√ªt**: $ (tr√®s √©conomique)
- **Fonctionnalit√©s**: Rapide, √âconomique
- **Cas d'usage**: T√¢ches g√©n√©rales, √©conomique

**Quand l'utiliser**:
- Environnement sans acc√®s Internet
- Budget tr√®s limit√©
- T√¢ches g√©n√©rales ne n√©cessitant pas de recherche web
- Tests et d√©veloppement

### 5. Llama 70B Instruct - Puissant üí™

**Nom complet**: `llama-3.1-70b-instruct`

- **Latence**: Moyenne (<800ms)
- **Qualit√©**: Excellente
- **Co√ªt**: $$ (mod√©r√©)
- **Fonctionnalit√©s**: Puissant, Pr√©cis
- **Cas d'usage**: Raisonnement complexe, qualit√© √©lev√©e

**Quand l'utiliser**:
- Raisonnement complexe sans besoin de recherche web
- Alternative √† Sonar Huge pour r√©duire les co√ªts
- Contexte priv√© n√©cessitant l'absence de recherche web

---

## üñ•Ô∏è Interface de S√©lection

### Lancement de l'Interface

```bash
# Depuis le r√©pertoire FilAgent
python gradio_app_model_selector.py
```

L'interface sera accessible sur: **http://localhost:7861**

### Fonctionnalit√©s de l'Interface

#### 1. Onglet "Chat avec Mod√®le"

- **S√©lecteur de mod√®le**: Dropdown pour choisir le mod√®le actif
- **Informations du mod√®le**: Affichage des caract√©ristiques du mod√®le s√©lectionn√©
- **Chat interactif**: Conversation avec le mod√®le s√©lectionn√©
- **M√©triques en temps r√©el**: Temps de r√©ponse, tokens utilis√©s
- **Exemples de questions**: Questions pr√©d√©finies par niveau de difficult√©

#### 2. Onglet "Comparaison de Mod√®les"

- **Test simultan√©**: Compare 3 mod√®les sur la m√™me question
- **Affichage c√¥te-√†-c√¥te**: R√©sultats format√©s en Markdown
- **M√©triques comparatives**: Temps, tokens, qualit√©
- **Questions de comparaison**: Exemples pour tester les diff√©rences

#### 3. Onglet "Informations Mod√®les"

- **Documentation compl√®te**: D√©tails de chaque mod√®le
- **Cas d'usage**: Quand utiliser chaque mod√®le
- **Caract√©ristiques techniques**: Latence, qualit√©, co√ªt

---

## üî¨ Scripts de Benchmark

### Script de D√©monstration Rapide

**Fichier**: `scripts/demo_model_comparison.py`

Teste **3 mod√®les** avec **1 question par niveau** de difficult√© (9 tests au total).

```bash
# Ex√©cution
pdm run python scripts/demo_model_comparison.py
```

**Sortie**: Rapport comparatif en console avec recommandations.

**Dur√©e**: ~2-3 minutes

### Script de Benchmark Complet

**Fichier**: `scripts/benchmark_perplexity_models.py`

Teste **5 mod√®les** avec **3 questions par niveau** de difficult√© (45 tests au total).

```bash
# Ex√©cution
pdm run python scripts/benchmark_perplexity_models.py
```

**Sorties**:
- `eval/benchmarks/perplexity/benchmark_YYYYMMDD_HHMMSS.json` (r√©sultats bruts)
- `eval/benchmarks/perplexity/benchmark_YYYYMMDD_HHMMSS.md` (rapport format√©)

**Dur√©e**: ~10-15 minutes

### Questions de Test par Niveau

#### FAIBLE Difficult√©
1. Quelle est la capitale du Qu√©bec?
2. Combien font 15% de 1000$?
3. Quel est le taux de TPS au Canada?

#### MOYEN Difficult√©
1. Explique les diff√©rences entre la Loi 25 du Qu√©bec et le RGPD europ√©en
2. Calcule le montant total TTC (TPS 5% + TVQ 9.975%) pour une facture de 2450$ HT
3. Quels sont les trois principaux risques juridiques pour une PME qu√©b√©coise qui utilise l'IA sans conformit√©?

#### √âLEV√â Difficult√©
1. Processus complet de mise en conformit√© Loi 25 pour un syst√®me d'IA d'analyse de CV
2. Comparaison de 3 mod√®les LLM pour une PME selon co√ªt, latence, qualit√© et conformit√©
3. Tra√ßabilit√© compl√®te pour une d√©cision automatis√©e de refus de cr√©dit selon Loi 25

---

## üéØ Recommandations par Difficult√©

### Configuration Recommand√©e

```yaml
# config/agent.yaml
model:
  backend: "perplexity"

  # S√©lection dynamique selon difficult√© de la requ√™te
  models:
    easy: "llama-3.1-sonar-small-128k-online"
    medium: "llama-3.1-sonar-large-128k-online"
    hard: "llama-3.1-sonar-huge-128k-online"

  # Ou mod√®le unique par d√©faut
  path: "llama-3.1-sonar-large-128k-online"
```

### Matrice de D√©cision

| Crit√®re | Small | Large | Huge | 8B | 70B |
|---------|-------|-------|------|-----|-----|
| **Latence < 300ms** | ‚úÖ | ‚ö†Ô∏è | ‚ùå | ‚úÖ | ‚ùå |
| **Qualit√© > 90%** | ‚ùå | ‚ö†Ô∏è | ‚úÖ | ‚ùå | ‚úÖ |
| **Recherche web** | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå |
| **Co√ªt $** | ‚úÖ | ‚ö†Ô∏è | ‚ùå | ‚úÖ | ‚ö†Ô∏è |
| **Raisonnement complexe** | ‚ùå | ‚ö†Ô∏è | ‚úÖ | ‚ùå | ‚úÖ |

**L√©gende**: ‚úÖ Excellent | ‚ö†Ô∏è Acceptable | ‚ùå Limit√©

### Par Cas d'Usage M√©tier

#### Comptabilit√© & Finance
- **Calculs simples** (TPS/TVQ): Sonar Small
- **Analyse financi√®re**: Sonar Large
- **Audit complexe**: Sonar Huge

#### Conformit√© & Juridique
- **V√©rification basique**: Sonar Small
- **Analyse r√©glementaire**: Sonar Large
- **D√©cisions automatis√©es**: Sonar Huge (**requis** pour Decision Records critiques)

#### Support Client
- **FAQ standard**: Sonar Small ou 8B Instruct
- **Questions techniques**: Sonar Large
- **Probl√®mes complexes**: Sonar Huge

#### Analyse de Documents
- **Extraction simple**: Sonar Small
- **Analyse s√©mantique**: Sonar Large
- **Analyse juridique**: Sonar Huge

---

## üìñ Guide d'Utilisation

### √âtape 1: V√©rifier la Cl√© API

```bash
# Assurez-vous que PERPLEXITY_API_KEY est configur√©e dans .env
grep PERPLEXITY_API_KEY .env
```

Si absente, ajoutez-la:
```bash
echo "PERPLEXITY_API_KEY=pplx-votre-cle-ici" >> .env
```

Obtenez une cl√© sur: https://www.perplexity.ai/settings/api

### √âtape 2: Installer les D√©pendances

```bash
# Le package openai est requis pour l'API Perplexity
pdm add openai
# Ou si d√©j√† install√©:
pdm sync
```

### √âtape 3: Tester avec la D√©monstration

```bash
# Test rapide (9 requ√™tes)
pdm run python scripts/demo_model_comparison.py
```

### √âtape 4: Lancer l'Interface Interactive

```bash
# Interface Gradio compl√®te
python gradio_app_model_selector.py
```

Acc√©dez √†: http://localhost:7861

### √âtape 5: Benchmark Complet (Optionnel)

```bash
# Benchmark exhaustif (45 requ√™tes)
pdm run python scripts/benchmark_perplexity_models.py
```

Consultez les r√©sultats dans: `eval/benchmarks/perplexity/`

### √âtape 6: Int√©gration dans FilAgent

Pour utiliser la s√©lection dynamique dans le code:

```python
from runtime.model_interface import init_model, GenerationConfig

# D√©terminer la difficult√© (√† impl√©menter selon votre logique)
difficulty = detect_query_difficulty(user_query)

# S√©lection du mod√®le
model_map = {
    "easy": "llama-3.1-sonar-small-128k-online",
    "medium": "llama-3.1-sonar-large-128k-online",
    "hard": "llama-3.1-sonar-huge-128k-online"
}

model_name = model_map[difficulty]

# Charger et utiliser
model = init_model(backend="perplexity", model_path=model_name, config={})
result = model.generate(prompt=user_query, config=GenerationConfig())
```

---

## üí° Bonnes Pratiques

### 1. D√©tection de Difficult√©

Impl√©mentez une logique de d√©tection bas√©e sur:
- **Longueur de la requ√™te**: Plus long = plus complexe
- **Mots-cl√©s**: "analyse", "compare", "explique en d√©tail" = complexe
- **Type de t√¢che**: Calcul simple vs raisonnement multi-√©tapes
- **Domaine**: Juridique/conformit√© = souvent complexe

### 2. Optimisation des Co√ªts

- Utilisez Sonar Small pour 60-70% des requ√™tes (FAQ, calculs)
- Sonar Large pour 25-30% (analyse standard)
- Sonar Huge pour 5-10% (d√©cisions critiques uniquement)

### 3. Monitoring

Suivez ces m√©triques:
- Latence moyenne par mod√®le
- Distribution des requ√™tes par mod√®le
- Co√ªt total par mod√®le
- Taux de satisfaction utilisateur par mod√®le

### 4. Conformit√© Loi 25

Pour les d√©cisions automatis√©es critiques:
- **Toujours utiliser** Sonar Huge ou 70B Instruct
- **G√©n√©rer un Decision Record** sign√©
- **Tracer la provenance** compl√®te
- **Permettre la contestation** avec explication

---

## üîß D√©pannage

### Erreur: "PERPLEXITY_API_KEY non d√©finie"

**Solution**: Configurez la cl√© dans `.env`:
```bash
echo "PERPLEXITY_API_KEY=votre-cle" >> .env
```

### Erreur: "Module 'openai' non trouv√©"

**Solution**: Installez le package:
```bash
pdm add openai
```

### Erreur: "Failed to load model"

**V√©rifications**:
1. Cl√© API valide
2. Nom du mod√®le correct (voir liste ci-dessus)
3. Connexion Internet active (pour mod√®les "-online")

### Interface Gradio ne se lance pas

**Solution**: V√©rifiez les d√©pendances:
```bash
pdm install -G ui  # Installe gradio
```

---

## üìä R√©sultats Attendus du Benchmark

Apr√®s ex√©cution du benchmark complet, vous devriez observer:

### Latence

- **Sonar Small**: 200-400ms
- **Sonar Large**: 400-700ms
- **Sonar Huge**: 700-1200ms
- **8B Instruct**: 150-300ms
- **70B Instruct**: 500-900ms

### Qualit√© (subjective)

- **Questions simples**: Tous mod√®les > 85%
- **Questions moyennes**: Large/Huge/70B > 80%, Small/8B ~70%
- **Questions complexes**: Huge/70B > 85%, Large ~75%, Small/8B < 65%

### Co√ªt Relatif (estim√©)

- **8B Instruct**: 1x (r√©f√©rence)
- **Sonar Small**: 1.5x
- **Sonar Large**: 2.5x
- **70B Instruct**: 3x
- **Sonar Huge**: 4x

---

## üéì Conclusion

Le syst√®me de s√©lection de mod√®les Perplexity permet √† FilAgent de:

1. **Optimiser les co√ªts** en utilisant le bon mod√®le au bon moment
2. **Maintenir la qualit√©** pour les t√¢ches critiques
3. **R√©duire la latence** pour les requ√™tes simples
4. **Respecter la conformit√©** avec Decision Records appropri√©s

**Recommandation g√©n√©rale**: Utilisez **Sonar Large** comme d√©faut, et ajustez selon le cas d'usage.

---

**Mise √† jour CLAUDE.md**: Ajoutez cette section √† votre fichier CLAUDE.md:

```markdown
## S√©lection de Mod√®les Perplexity

FilAgent supporte 5 mod√®les Perplexity avec s√©lection dynamique:

- **sonar-small-128k-online**: Rapide, questions simples
- **sonar-large-128k-online**: √âquilibr√© (recommand√© par d√©faut)
- **sonar-huge-128k-online**: Maximum qualit√©, raisonnement complexe
- **8b-instruct**: √âconomique, sans web
- **70b-instruct**: Puissant, sans web

**Interface interactive**: `python gradio_app_model_selector.py` (port 7861)
**Benchmark**: `scripts/benchmark_perplexity_models.py`
**Documentation**: `docs/GUIDE_SELECTION_MODELES_PERPLEXITY.md`
```

---

**Auteur**: FilAgent Team
**Date**: 2025-11-17
**Version**: 1.0.0
