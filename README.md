# **LLM-Agent : Gouvernance & Tra√ßabilit√©**

Ce projet vise √† d√©velopper un agent bas√© sur un Grand Mod√®le de Langage (LLM) avec un accent fondamental sur la gouvernance, la tra√ßabilit√© l√©gale, la s√©curit√© et la reproductibilit√© des d√©cisions. L'architecture est con√ßue pour √™tre ex√©cutable localement tout en respectant des normes de conformit√© strictes (Loi 25 du Qu√©bec, AI Act de l'UE, NIST AI RMF).

## **üéØ Objectifs Principaux**

1. **M√©moire G√©r√©e :** Mettre en place une m√©moire √† court et long terme avec un contr√¥le strict des consentements et une minimisation des donn√©es.  
2. **Interpr√©tations Logu√©es :** Assurer que chaque action, d√©cision et interaction de l'agent soit enregistr√©e dans un journal immuable (WORM) et analysable.  
3. **Tra√ßabilit√© L√©gale :** Garantir la capacit√© de reconstruire et d'expliquer une d√©cision automatis√©e, conform√©ment aux exigences l√©gales (notamment l'ADM de la Loi 25).  
4. **Capacit√©s d'Agent Avanc√©es :** Viser des performances √©gales ou sup√©rieures aux standards de l'industrie (Codex, agents avanc√©s) sur des t√¢ches de raisonnement et de manipulation d'outils, valid√©es par des benchmarks rigoureux.

## **‚ú® Fonctionnalit√©s Cl√©s**

* **Moteur de Politiques (Policy Engine) :** Contr√¥le en amont de chaque action pour le masquage de PII, la v√©rification des droits et la conformit√© juridictionnelle.  
* **Ex√©cution S√©curis√©e (Sandboxing) :** Isolation compl√®te de l'ex√©cution de code et des outils pour pr√©venir les risques de s√©curit√©.  
* **Journalisation WORM :** Utilisation de cha√Ænes de hachage (Merkle Tree) pour garantir l'int√©grit√© et l'immuabilit√© des journaux d'audit.  
* **G√©n√©ration de "Dossiers de D√©cision" :** Capacit√© √† produire un rapport structur√© pour chaque d√©cision, expliquant les entr√©es, les r√®gles appliqu√©es et les sorties.  
* **Reproductibilit√© :** Versionnement strict des mod√®les, des param√®tres (seed, temp√©rature) et des politiques pour garantir des r√©sultats reproductibles.  
* **√âvaluation Continue :** Int√©gration d'un harnais d'√©valuation continue bas√© sur des benchmarks standards (HumanEval, MBPP, SWE-bench-lite).

## **üõ†Ô∏è Architecture Technique**

Le projet est structur√© autour d'une arborescence claire, s√©parant la configuration, les mod√®les, la m√©moire, les logs, les outils et l'√©valuation.

* **Inf√©rence Locale :** Le syst√®me est con√ßu pour utiliser des mod√®les locaux (ex: via llama.cpp ou vLLM) afin de garantir la confidentialit√© des donn√©es.  
* **M√©moire Hybride :** Combine une m√©moire √©pisodique (SQLite) pour le contexte de la conversation et une m√©moire s√©mantique (FAISS/Parquet) pour la recherche de connaissances √† long terme.  
* **Observabilit√© :** Les logs sont structur√©s au format JSONL compatible OpenTelemetry pour une analyse et une surveillance facilit√©es.  
* **Provenance :** Chaque artefact g√©n√©r√© est accompagn√© de m√©tadonn√©es de provenance suivant le standard W3C PROV-JSON.

## **üöÄ D√©marrage Rapide (Getting Started)**

### Pr√©requis

- Python 3.10 ou sup√©rieur
- Git
- 8+ GB de RAM (16GB recommand√©)
- Optionnel : GPU NVIDIA pour acc√©l√©ration

### Installation

```bash
# 1. Cloner le d√©p√¥t
git clone https://github.com/votre-org/FilAgent.git
cd FilAgent

# 2. Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# 3. Installer les d√©pendances
pip install -r requirements.txt

# 4. T√©l√©charger un mod√®le
# Voir models/weights/README.md pour les instructions d√©taill√©es
mkdir -p models/weights
# Exemple avec Llama 3 :
cd models/weights
wget https://huggingface.co/TheBloke/Llama-3-8B-Instruct-GGUF/resolve/main/llama-3-8b-instruct.Q4_K_M.gguf -O base.gguf
cd ../..

# 5. Initialiser la base de donn√©es
python -c "from memory.episodic import create_tables; create_tables()"
```

### Configuration

Les configurations par d√©faut sont dans `config/`. Vous pouvez les ajuster :

- `config/agent.yaml` : Param√®tres de g√©n√©ration, mod√®le, m√©moire
- `config/policies.yaml` : R√®gles d'usage, RBAC, guardrails
- `config/retention.yaml` : Politiques de r√©tention des donn√©es
- `config/provenance.yaml` : Configuration de tra√ßabilit√©
- `config/eval_targets.yaml` : Seuils d'√©valuation

### Lancement

```bash
# Lancer le serveur API
python runtime/server.py

# Le serveur sera accessible sur http://localhost:8000
# Documentation API sur http://localhost:8000/docs
```

### Test rapide

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Bonjour !"}],
    "conversation_id": "test-123"
  }'
```

Pour plus de d√©tails, voir [README_SETUP.md](README_SETUP.md)

## **‚öñÔ∏è Conformit√© et Gouvernance**

Ce projet int√®gre d√®s sa conception les cadres de gouvernance suivants :

* **ISO/IEC 42001 :** Syst√®me de management de l'IA.  
* **NIST AI RMF 1.0 :** Cadre de gestion des risques de l'IA.  
* **Loi 25 (Qu√©bec) :** Transparence et explicabilit√© des d√©cisions automatis√©es.  
* **AI Act (UE) :** Exigences de tra√ßabilit√© et de transparence.